#### http协议

##### 特点
- HTTP 是灵活可扩展的，可以任意添加头字段实现任意功能；
- HTTP 是可靠传输协议，基于 TCP/IP 协议“尽量”保证数据的送达；
- HTTP 是应用层协议，比 FTP、SSH 等更通用功能更多，能够传输任意数据；
- HTTP 使用了请求 - 应答模式，客户端主动发起请求，服务器被动回复请求；
- HTTP 本质上是无状态的，每个请求都是互相独立、毫无关联的，协议不要求客户端或服务器记录请求相关的信息。
- 应用层-短连接-无状态

缺点：
- 明文不安全
- 传输了大量的头    

##### 状态码：
- 200：成功
- 301：永久重定向
- 302：临时重定向
- 304：访问了缓存
- 401：权限不足
- 403：资源禁止访问
- 404：客户端错误
- 500： 服务器端错误
- 502：请求无法及时发送到后端

http 协议格式：
请求行-请求头部-空行-请求体
状态行-响应头-空行-响应体

一些头：
- Content-Type
- Content-Encoding
- Content-Language

##### http 传输大文件
- 压缩 HTML 等文本文件是传输大文件最基本的方法；
- 分块传输可以流式收发数据，节约内存和带宽，使用响应头字段“Transfer-Encoding: chunked”来表示，分块的格式是 16 进制长度头 + 数据块；
- 范围请求可以只获取部分数据，即“分块请求”，实现视频拖拽或者断点续传，使用请求头字段“Range”和响应头字段“Content-Range”，响应状态码必须是 206；
- 也可以一次请求多个范围，这时候响应报文的数据类型是“multipart/byteranges”，body 里的多个部分会用 boundary 字符串分隔。

#### HTTP 2.0
- 头部压缩(HPACK): 在两端建立头部 key-value 的索引表，传输的时候，对相同的头只发送索引
- 虚拟的流：将一个TCP连接切分成多个流，每个流有自己的ID，且可以向对方发送消息，流式一个虚拟的通道，有优先级
- 二进制格式：将消息分为更小的消息和帧，并采用二进制编码，Header 帧用于传输 Header 并开启一个新的流，Data 帧传输正文实体，多个Data属于同一个流  

HTTP 2.0 通过上述方式将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。  

而实际上，HTTP2.0其实只是将三个请求变成三个流，将数据分成帧，乱序发送到一个TCP连接中。所以依然受到 TCP 严格顺序的限制，当前面stream 2的帧没有收到，后面stream 1的帧也会因此阻塞。

#### QUIC
QUIC 的基本数据传输单位是包（packet）和帧（frame），一个包由多个帧组成，包面向的是“连接”，帧面向的是“流”。  

UDP 发生是不管顺序，也不管丢包的，所以不会出现 HTTP/1.1 的队头阻塞 和 HTTP/2 的一个丢包全部重传问题。

##### 自定义连接机制
tcp 通过源IP，源端口，目标IP，目标端口 标识一个连接，其中一个元素变了，就需要重新三次握手。  、
QUIC 基于UDP，设计了根据一个 64 位随机数作为连接标识，当IP或端口变化时，只要ID不变，就不需要重新建立连接

##### 自定义重传机制
TCP 通过序号和确认序号，保证顺序问题和丢包问题。  

QUIC 的每个数据包也有一个序列号，但是是递增的，这样就可以准确的计算 rtt 时间，通过 offset 判断是否是同一个数据包

##### 无阻塞多路复用
同HTTP 2.0一样，同一条QUIC连接上可以创建多个stream，来发送多个 HTTP 请求。但是，QUIC是基于UDP的，一个连接上的多个stream之间没有依赖。这样，假如stream2丢了一个UDP包，后面跟着stream3的一个UDP包，虽然stream2的那个包需要重传，但是stream3的包无需等待，就可以发给用户。

##### 自定义流量控制
不但在一个连接上控制窗口，还在一个连接中的每个stream控制窗口。

TCP 中应答了一个包，就表示它之前的包应答过了，所以在窗口中，即使后面的包以及接收到了，也只能在窗口中缓存而不进行应答，这样就有可能因为前面的包丢失而导致后面已经接收包超时发起重发，浪费宽带。    

QUIC的ACK是基于offset的，每个offset的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空挡会等待到来或者重发即可

#### https 过程
1. ClientHello
客户端主要向服务器发送以下信息：
- 客户端支持的 SSL/TLS 协议版本，如 TLS 1.2 版本
- 客户端生产的随机数（Client Random），后面用于生产`会话秘钥`。
- 客户端支持的密码套件列表，如 RSA 加密算法

2. SeverHello
服务器回应的内容有如下内容：
- 确认 SSL/ TLS 协议版本，如果浏览器不支持，则关闭加密通信。
- 服务器生产的随机数（Server Random），后面用于生产`会话秘钥`。
- 确认的密码套件列表，如 RSA 加密算法。
- 服务器的数字证书。

3. 客户端回应
通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。
如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：
- 一个随机数（pre-master key）。该随机数会被服务器公钥加密。
- 加密通信算法改变通知，表示随后的信息都将用`会话秘钥`加密通信。
- 客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。

上面第一项的随机数是整个握手阶段的第三个随机数，这样服务器和客户端就同时有三个随机数，接着就用双方协商的加密算法，各自生成本次通信的`会话秘钥`。

4. 服务器的最后回应
服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的 `会话秘钥`。然后，向客户端发生最后的信息：
- 加密通信算法改变通知，表示随后的信息都将用`会话秘钥`加密通信。
- 服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。

至此，整个 SSL/TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用`会话秘钥`加密内容。

##### 密码套件的含义 如 ECDHE-RSA-AES256-GCM-SHA384
含义：密钥交换算法 + 签名算法(对指纹`签名验签`，`身份认证`) + 对称加密算法(`机密性`) + 摘要算法(指纹，`完整性`)  

握手时使用 ECDHE 算法进行密钥交换，用 RSA 签名和身份认证，握手后的通信使用 AES 对称算法，密钥长度 256 位，分组模式是 GCM，摘要算法 SHA384 用于消息认证和产生随机数。  

- 公钥加密私钥解密，私钥加签公钥解签

##### 加密
对称AES,非对称RSA



##### 网络分层模型
- TCP/IP 四层模型
- OSI 七层模型

##### 什么是二层转发，三层路由
- 设备工作在链路层，帧在经过交换机设备时，检查帧的头部信息，拿到目标mac地址，进行本地转发和广播
- 三层路由：设备工作在ip层，报文经过有路由功能的设备时，设备分析报文中的头部信息，拿到ip地址，根据网段范围，进行本地转发或选择下一个网关

##### DNS
- DNS 是一个树状的分布式查询系统，但为了提高查询效率，外围有多级的缓存；
- 使用 DNS 可以实现基于域名的负载均衡，既可以在内网，也可以在外网。


##### json web token
- 客户端使用用户名和密码登录
- 服务端收到请求后会去验证用户名和密码，如果成功，就签发一个token返回客户端
- 客户端收到请求后会将 token 缓存起来，放到 cookie或local storage，每次请求都带 token
- 服务端验证token

token 组成：
- header
```
{
  "typ": "JWT",
  "alg": "HS256"
}
```
- payload
```
{
 "id": 2,
 "username": "kong",
 "nbf": 1527931805, # 生效时间
 "iat": 1527931805  # 签发时间
}
```

- signature
```
用 base64 对 header 和 payload 编码，用 secret 对编码加密
```
#### websocket

HTTP/2 针对的是“队头阻塞”，而 WebSocket 针对的是“请求 - 应答”通信模式。


websocket HTML5支持的是全双工的通信协议，http协议是单工的，所以以前常常使用轮询模拟双工。

- 客户端通过 http 请求与 websocket 服务端协商服务升级，升级后，后续数据传输就按照 websocket 协议进行
```
GET / HTTP/1.1
Host: localhost:8080
Origin: http://127.0.0.1:3000
Connection: Upgrade             # 表示要升级协议
Upgrade: websocket              # 表示要升级到websocket协议
Sec-WebSocket-Version: 13       # 表示websocket的版本
Sec-WebSocket-Key: w4v7O6xFTi36lq3RNcgctw==  # 验证连接
```

- 服务端响应服务升级
```
HTTP/1.1 101 Switching Protocols
Connection:Upgrade
Upgrade: websocket
Sec-WebSocket-Accept: Oy4NRAQ13jhfONC7bP8dTKb4PTU=
```

#### auth2.0 四种获取token的方式
- 授权码：第三方应用现申请一个授权码，再用授权码去获取 token，这种方式安全性最高
- 隐藏式: 授权码方式的简化版，直接返回token
- 密码式：
- 凭证式: 用在命令行模式


### tcp 和 udp 的区别

 -| TCP | UDP |
---|--- | --- |
连接| 互通前需要建立连接| 不需要
可靠性 | 保证可靠，无差错，不重复，按序到达| 不保证
数据类型 | 将ip包封住为字节流式，基于字节流 | 保持IP 包的特性，基于数据报
拥塞控制 | 是 | 否
有状态 | 是 | 否

### TCP
- 序号(32位)： 解决乱序问题
- 确认序号(32位): 解决丢包问题, 累计确认，累计应答
- 状态位： SYN(发起连接),ACK(回复),RST(重新连接),FIN(结束连接)， 维护连接两端的状态
- 窗口大小：标识自己的处理能力，连接双端通过窗口大小做流量控制，拥塞控制
- 

##### 为什么要进行3此握手？
为了防止已失效的连接请求报文段突然又传送到了服务端，因而产生错误，造成服务器的等待，浪费资源
##### 四次分手为什么要有 2 MSL 等待延迟
对应这样一种情况，最后客户端发送的ACK = 1给服务端的过程中丢失了，服务端没收到，服务端怎么认为的？我已经发送完数据了，怎么客户端没回应我？是不是中途丢失了？然后服务端再次发起断开连接的请求，一个来回就是2MSL，这里的两个来回由那一个来回组成的？

客户端给服务端发送的ACK = 1丢失，服务端等待 1MSL没收到，然后重新发送消息需要1MSL。如果再次接收到服务端的消息，则重启2MSL计时器，发送确认请求。客户端只需等待2MSL，如果没有再次收到服务端的消息，就说明服务端已经接收到自己确认消息；此时双方都关闭的连接，TCP 四次分手完毕。 
##### 重传机制
- 超时重传：重试重传时间(RTO)是动态变化的. 采样(往返时间)RTT 和 采样 RTT 的波动范围()，加权平均
- 快速重传：不以时间为驱动，而是以数据为驱动。依次发送seq1，seq2，seq3 只收到了 ack2(对应 seq1).无法判断，seq2,seq3那个是不是都没成功，可能需要全部重传。为了避免全部重传，可以启用 SACK,或 DSACK(Linux2.4后默认)
##### 流量控制-滑动窗口
接收方通过返回窗口大小，控制发送方发送的速度

- 窗口大小表示：无需等待确认应答，可以继续发送数据的最大值
- TCP 应答是累计应答,比如发送了 seq1,seq2,seq3,只要收到了 ack4,就可以认为三个都成功了
- 窗口大小是接收方决定的，接收方告诉发送方自己的处理能力，发送方据此调整窗口大小
- 发送方可以分为四个部分，2，3 表示窗口: 1. 已发送并收到 ACK 确认的数据 2. 已发送 ACK 但未确认的数据 3. 未发送但在处理能力内的数据 4. 未发送，超出处理能力的数据
- 接收方窗口可以分为三个部分， 2 表示窗户口：1. 已成功接收并确认的数据 2.未收到数据但可以接收的数据 3. 未接收到，并不可以接收的数据

##### 拥塞控制(控制单次发送量)
发送的包没有收到响应，有两种可能，一是请求丢失，二是请求还没到接收方。拥塞控制是为了处理第二种请求，如果是请求还没到，但是依然重传的话，会造成网络更拥堵。

流量控制是避免「发送方」的数据填满「接收方」的缓存。 拥塞控制，控制的目的就是避免「发送方」的数据填满整个网络。

为了在「发送方」调节所要发送数据的量，定义了一个叫做「拥塞窗口」的概念。  

拥塞窗口 cwnd是发送方维护的一个 的状态变量，它会根据网络的拥塞程度动态变化的。  

只要「发送方」没有在规定时间内接收到 ACK 应答报文，也就是发生了超时重传，就会认为网络出现了用拥塞。

拥塞控制有哪些控制算法：
- 慢启动：发送的包呈指数性增长，超过一般来说 ssthresh 的大小是 65535 字节后，使用下面的拥塞避免算法
- 拥塞避免：线性增长。每当收到一个 ACK 时，cwnd 增加 1/cwnd。从这里开始慢慢会进入拥塞状态，开始出现丢包现象触发重传机制，这时就会进入下面的拥塞发生算法
- 拥塞发生：重传的方式不一样，拥塞发生算法的行为也不一样
  - 发生超时重传：cwnd 变为 1， ssthresh 变为 cwnd /2， 相当于急刹车，重新开始慢启动...
  - 发生快速重传：cwnd = cwnd/2， ssthresh = cwnd， 并进入下面的快速回复算法
- 快速恢复： cwnd = ssthresh + 3，重传丢失的数据包，如果再收到重复的 ACK，那么 cwnd 增加 1， 进入拥塞避免算法

##### TCP 粘包是个啥？
TCP 是面向字节流的协议，不负责理解数据包的规则，这个问题应该通过应用层去解决，比如 http 的 header 里会说明 content-Length。  
不定长消息，不经过消息头校验，和消息尾分割，就会出现粘包。
为什么会发生所谓的粘包：
- 写入的数据大于套接字缓冲区，会拆包
- 写入的数据小于套接字缓冲区，会粘包
- 接收方不及时读取套接字缓冲区数据，会粘包
- 进行 MSS （最大报文长度）大小的 TCP 分段，当 TCP 报文长度-TCP 头部长度>MSS 的时候将发生拆包。

解决办法：
- 使用带消息头的协议，比如 HTTP，消息头存储消息开始标识及消息长度信息，服务端获取消息头的时候解析出消息长度，然后向后读取该长度的内容。
- 设置定长消息，服务端每次读取既定长度的内容作为一条完整消息，当消息不够长时，空位补上固定字符。
- 设置消息边界，服务端从网络流中按消息编辑分离出消息内容，一般使用‘\n ’。

UDP 中有记录数据报的长度，所以不存在粘包问题。TCP 是基于字节流的，没有区分数据包的边界，仅仅是一连串没有结构的字节流。