#### 事务、锁
##### 避免长事务
长事务意味着需要存很多视图，导致占用大量的存储空间。  
- 设置 `set autocommit = 1`, 显式声明事务的开始和结束
- 去掉不必要的只读事务
- 根据业务预估事务执行的时间，设置合适的 `MAX_EXECUTION_TIME`
- 监控 `information_schema.Innodb_trx` 表，发现长事务就报警或 kill 掉
- 测试阶段要求输出 general_log 日志，分析日志行为提前发现问题
- 尝试使用 pt-kill 工具

##### 锁的一些概念
###### 全局锁
全局锁会使数据库的写操作全部停止，它的应用场景一般是做全库的逻辑备份，通过 Flush tables with read lock (FTWRL) 加锁，然后做备份。  
对于不支持事务的存储引擎通常是采用这种方式的。  
对于支持事务的存储引擎可以通过开启一个事务的方式，拿到当前时间节点的视图，对这个视图进行备份。
###### 表级锁
表级锁用两种: 1. 表锁 2. 元数据锁(MDL)  

表锁 lock tables ...read/write 可以用unlock tables主动释放锁，这种方式除了限制了别的线程的读写外，也限制了当前线程接下来的操作对象，比如:  
执行 `lock table t1 read,t2 write`，除了会导致其他连接不能对 t1 写，不能对 t2 读写外，还会导致当前连接不能对 t1 写。  

MDL 不需要显示的声明，在访问一个表时会被自动加上。当对一个表做 DML 操作的时候，加MDL读锁;当要对表 DDL 操作的时候，加MDL写锁。  
读锁之间不互斥，因此可以有多个线程同时对一张表增删改查。读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线 程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。  
MDL会直到事务提交才释放, 所以如果存在长事务，在修改表结构的时候，可能会造成长时间的阻塞。

###### 行级锁
行锁是在引擎层实现的。在 Innodb 中行锁是在需要的时候才加上的，但并不是不需要了就马上释放，而是等到事务提交了才会释放锁(两阶段锁协议)。如果事务中需要锁多个行，要把最可能造成冲突，最可能影响并发度的锁尽量往后放，这样可以最大程度的减少事务之间的锁等待。  

行级锁的粒度最小，也最容易放生死锁。为了避免死锁将 CPU 打爆，有两种方法：  
1. 设置锁等待超时时间 `innodb_lock_wait_timeout`, 
2. 发起死锁检测，设置 `innodb_deadlock_detect` 为on, 发现死锁后，主动回滚死锁链条中某一个事务，让另一个事务得以继续运行 (推荐此方法)

为了在大量更新同一行数据时引起的大量的死锁检测：  
1. 修改数据库源码，对同一行的修改请求，在请求进入引擎前排队
2. 将单行数据分成多行 

隔离级别的实现：  
- Innodb 的行数据通过 undolog 逻辑上维护了多个版本，每个版本有自己的 row trx_id, ，每个事务或者语句都有自己的一致性视图。
- 对于可重复读，查询只承认在事务启动前就已经提交完成的数据；对于读提交，查询只承认在语句启动前就已经完成提交的数据。

#### 索引
##### Innodb 的索引模型
在 Innodb 中，表是根据主键顺序以索引的形式存放的，每个索引都是一个 b+ 树。  
主键索引的叶子节点存的是数据本身，所以又被称为聚簇索引；普通索引的叶子节点存的是主键的值，所以又被称为二级索引。  
对于主键索引的查询只需要扫描一次索引树，对于普通索引，需要扫描两次索引树。  

对于 Innodb， 主键索引应该尽量使用自增整数，这样可以减少普通索引占用的磁盘空间，除非表里只需要一个主键。  

##### 为什么数据库使用 b+ 树
- 树形结构插入和查询速度都快，也适合做范围查询
- 多叉树可以减少磁盘访问次数

##### 索引的一些概念
- 覆盖索引：查询一次索引树就可以，不需要回表
- 左前缀原则：
- 索引下推：mysql 5.6 后的优化，使用联合索引时，不符合最前缀的部分，会先对索引中包含的字段的条件进行筛选

##### 为什么要重建索引
索引可能因为删除， 或者页分裂等原因， 导致数据页有空洞， 重建索引的过程会创建一个新的索引， 把数据按顺序插入， 这样
页面的利用率最高， 也就是索引更紧凑、 更省空间

##### sql未能使用索引的一些坑
- 对索引字段做函数操作，会破坏索引值的有有序性，致使优化器放弃走索引
- 索引字段上的隐式类型转换和隐式字符编码转换，会被mysql在字段上执行函数操作，导致放弃索引

##### Change Buffer
作用： 
- 减少读磁盘随机IO
- 因为数据的读入是占用 Buffer Pool 的，所以使用 Change Buffer 还可以避免内存占用，提高内存使用率。

使用过程：   
当需要更新一个数据页时，如果数据页在内存中就直接更新，如果在磁盘中，就先将这些更新操作缓存在 Change Buffer 中，在下次需要查询该数据页时，先
将数据页从磁盘中读入内存，再对其执行 Change Buffer 中的操作，这样就可以保证数据的逻辑正确性。

应用场景：  
Change Buffer 用于减少`写多读少`的场景下写操作引起的随机IO，但仅限于在普通索引上使用。不适用于写完后立即读的场景，因为这种场景下会立即出发
Merge 操作，这样随机 IO 次数不会减少，还会增加维护 Change Buffer 的消耗。 

redo log 主要节省的是随机写磁盘的IO消耗； change buffer 主要节省的是随机读磁盘的IO消耗。
#### 日志
##### redo log（引擎层 Innodb 引擎特有的日志）
使用 WAL(write ahead log) 机制，先将写操作记录到 `redo log` 并更新内存，再在系统空闲时将操作记录更新到磁盘。
`Redo log` 是固定大小的循环数组，在它上面维护了两个变量，`check_point` 和 `write_pos`： 
- `check_point` 表示已经同步到磁盘的位置，向后推移
- `write_pos` 表示已经日志记录的当前位置，向后推移  

如果 `write_pos` 追上了 `check_point` 就表示 `redo log` 满了，需要立即执行同步磁盘的操作推进 `check_point`  

因为有了 Redo log， 所以 mysql 在意外宕机后，之前提交的记录都不会丢失。  

##### binlog (Server 层日志)
redo log 是物理日志，记录在数据页上做了什么修改；binlog 是逻辑日志，记录的是原始sql语句。

##### Innodb 更新数据使用 redolog 和 binlog 的两阶段提交

更新流程：
- 执行器通过引擎将数据读入内存
- 执行器执行修改数据操作，并调用引擎的写数据接口
- 引擎将新数据更新到内存中，同时将更新操作记录到 redo log 中，此时 redo log 处于 prepare 状态。告知执行器执行完成，可以提交事务。
- 执行器生成这个操作的 binlog， 并将 binlog 写入磁盘
- 执行器调用引擎提交事务接口，引擎将 redo log 的状态改为 commit 状态，更新完成。

两阶段提交可以保证 redo log 和 binlog 逻辑上的一致。

#### 内存占用的可能原因
##### Mysql 长连接引起的 OOM 
因为建立连接比较复杂，所以建议使用长连接。但由于mysql执行过程中的临时使用的内存是连接对象管理的，
所以，连接长时间不关闭会导致内存占用，有两种解决方法：  
- 定期断开长连接，或者在程序中判断，执行了一个占用大量内存的查询后，主动断开连接
- 5.7版本后，在执行占用内存大的查询后，执行 `mysql_reset_connection` 可以初始化连接资源，此操作不需要重连和权限验证
##### 大量的写操作没有使用到 Change Buffer，只有普通索引能用上ChangeBuffer 


#### 隔离级别
##### 幻读
- 在可重复读隔离级别下，普通的查询表是快照读，不会看到其他事务插入的数据，幻读在"当前读"下才会出现
- 幻读仅专指"新插入的行"

Innodb 使用间隙锁解决幻读问题：  
- 再给行加锁的同时，给行的两边加入相应的前开后闭的间隙锁
- 间隙锁只在可重复读的隔离级别下才会生效
- 间隙锁的引入导致语句锁住更大的范围，会影响并发度

`读提交的级别下，没有间隙锁，但会出现数据和日志不一致的情况，需要把binlog设置为row `


#### 其他问题
##### sql 语句偶尔的执行变慢(刷脏页 flush)  
触发 flush 的情况：  
- redo log 写满了， 需要停止所有更新操作，推进 checkpoint。这种情况应该竭力避免。
- 系统内存不足，需要淘汰掉一些数据页释放内存，如果淘汰的是数据页是"脏页"，就要先将脏页写到磁盘。
- 系统空闲时自动进行 flush
- mysql 正常关闭时

InnoDB 刷脏页的控制策略：  
- 正确配置参数 `innodb_io_capacity`
- 观察脏页比例，不要经常超过 75%
- 配置参数`innodb_flush_neighbors`在机械硬盘中设置为 1， SSD 中设置为 0

##### 删除表数据不能回收磁盘空间
delete 命令其实只是把记录的位置， 或者数据标记为了"可复用"， 但磁盘文件的大小是不会变的。  
可复用但还没有被使用的空间，就像空洞，增删改都会造成这种空洞。  
要消除这种空洞只能通过重建表的方式。

##### count 行数
MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数；  
InnoDB 执行count(*) 需要把数据一行行从引擎里读出来累计计算，MySQL 优化器会找到最小的索引树去遍历，尽量减少扫描的数据量。

##### 排序要注意的问题
如果内存足够MySQL会选择全字段排序(将所有要返回的字段都放入 sort_buffer 中)，
如果内存不够MySQL会使用 row_id 排序(仅将需要被排序的字段和id存入sort_buffer, 最后根据排序好的id去原表取值)；

不论是那种排序方法，如果内存不够，都会使用磁盘创建临时文件，使用归并排序进行排序。  

优化排序：
- 为筛选条件和排序字段建立联合索引，这样的排序不需要 `Using filesort`
- 为返回字段，帅选条件，排序字段建立联合索引，使排序sql可以使用覆盖索引。

##### 排查查询慢的原因
###### MDL 锁
执行 `show processlist` 命令查看当前语句的状态
state 处于 `waiting for table metadata lock` 表示有一个线程持有 MDL 写锁，通过查询 sys.schema_table_lock_waits 这张表， 
可以找出造成阻塞的 process id， 把这个连接用 kill 命令断开即可。

###### 等 flush
当 `flush tables` 被阻塞后，再执行查询语句，也会被阻塞
###### 等行锁
当一个事务持有某一行的行锁且没有提交，那么关于这一行的查询语句将会被阻塞，可以如此排查：

`select * from t sys.innodb_lock_waits where locked_table=`'{db_name}'.'{table_namn}'`\G`  

###### 没有利用索引

###### 一致性读，需要执行大量的 redo log

##### `lock in share mode` vs `for update`

lock in share mode适用于两张表存在业务关系时的一致性要求，for  update适用于操作同一张表时的一致性要求。  

使用 SELECT FOR UPDATE 为 update 操作锁定行，只适用于 autocommit 被禁用（当使用 START TRANSACTION 开始事务或者设置 autocommit 为0时）



 