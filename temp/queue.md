# kafka
##### 基本术语
- Topic：发布订阅的对象
- Producer: 生产者向一个或多个主题发送消息
- Consumer: 消费者消费一个或多个主题
- Client: Producer 和 Consumer 统称为 Client
- Broker: 服务器端，集群由多个 Broker 节点组成，实现高可用
- Partition: 分区。每个Topic划分多个Partition，实现高可扩展性，每个分区可配置一个Leader Replica 和 N-1 个Follower Replica。分区的设计主要是为了负载均衡。
- Replica: 副本，分区级别，用于实现高可用。
- Leader Replica：领导者副本，对外提供服务
- Follower Replica: 仅追随领导者副本，不对外提供服务
- Log: 使用顺序IO持久化的消息日志，是Kafka高吞吐的一个原因
- Log Segment: 一个Log会分为多个Log Segment，当一个 Log Segment 写满后，会自动切分出一个新的 Log Segment。后台有定时任务会检查老的日志段是否能被删除，实现回收磁盘的目的
- Consumer Group: 消费者组，为了同时实现 Peer To Peer 模型，和Publish/Subscribe模型。使消费者具有可扩展性和容错性。
- Offset: 每条消息在分区中的位置
- Consumer Offset：消费者位移，记录消费者当前消费到了分区的那个 Offset 上。表示下一条要消费的位移
- Rebalance: 消费者组内某个消费者实例挂掉后，其他消费者实例自动重新分配订阅主题分区的过程

##### kafka 的作用
- 削峰填谷，使下游有能力应对上游的流量冲击。
- 系统解耦，消息的发送方和接收方松耦合，简化应用开发，减少不必要的调用
- 纯二进制传输
- 
##### kafka 对比 rabbitmq
- rabbitMQ 属于传统消息队列系统，支持标准的消息队列协议(AMQP,STOMP,MQTT)，如果应用需要支持这些协议，就选择 RabbitMQ.
- rabbitMq 支持负载的 consumer routing
- kafka 优势在于高吞吐量和数据持久化，已实现业务系统为主要目标，可以考虑 rabbitmq
- kafka 不支持消息放入延迟队列重试
- kafka 消费有超时时间，rabbitmq 没有

##### kafka Follower副本不对外提供服务的原因
- Follower 拉去 Leader 副本可能之后放，影响实时性。
- 分区已经实现了可以从多个节点消费消息
- 消费者Offset的控制会更复杂   


##### kafka Stream 的优势
- 正确性，数据流转和计算都在kafka内部完成，可以实现端到端的精确一次处理语义
- 小。

##### 分区策略
- 轮询
- 随机
- 指定Key，比如业务中的某ID， 或按区域划分

##### 生产者丢失数据
生产者API没有处理 error， 因为网络抖动或数据校验不通过的情况，消息可能没有发到 broker 或没有被 broker 提交
##### 消费者丢失数据
要注意先消费消息，再更新位移，使用手动提交位移

新加分区，生产者先感知到，并发送一些数据，如果配置 `auto.offset.reset=latest`， 那么消费者将丢失这一段时间的消息

##### 消息语义
- 最多一次（at most once）：消息可能会丢失，但绝不会被重复发送。producer 关闭重传
- 至少一次（at least once）：消息不会丢失，但有可能被重复发送。producer 开启重传
- 精确一次（exactly once）：消息不会丢失，也不会被重复发送。producer 开启幂等性(enable.idempotence),broker 会对消息去重，但是是分区级别的。如果想要Topic级别的精确一次语义保证，就要使用到事务，producer开启事务需要设置配置(transctional. id),消费者端也要改变`isolation.level`, 由默认的`read_uncommitted` 改为 `read_committed`.

##### Rebalance 
规定了一个 Consumer Group 下的所有 Consumer 如何达成一致，来分配订阅 Topic 的每个分区。比如某个 Group 下有 20 个 Consumer 实例，它订阅了一个具有 100 个分区的 Topic。正常情况下，Kafka 平均会为每个 Consumer 分配 5 个分区。  

触发条件：
- 组内的 Consumer 数量变化
- 订阅的主题数发生变化，比如使用正则的方式订阅主题，主题的数量可能是经常变化的
- 订阅主题的分区数发生变化。

##### 避免非必要的 Rebalance
- 设置心跳超时时间 session.timeout.ms
- 设置心跳周期时间 heartbeat.interval.ms， session.timeout.ms 应该是 heartbeat.interval.ms 的三倍以上
- 设置消费者消费时间 max.poll.interval.ms， 评估消费者消费一条消息的时间，以此设置对应的值


##### consumer 位移提交
`消费者提交位移，如果提交了靠后的位移，会造成数据丢失，如果提交了消费过的位移，会造成重复消费` 

位移提交可以分为自动提交和手动提交。自动提交需要设置`enable.auto.commit`为true，且要合理设置 `auto.commit.interval.ms` 自动提交频率，在发生 Rebalance后，可能会重复消费一个自动提交周期内的消息。  

手动提价位移，又有同步和异步之分。同步模式在提交时，会阻塞 Consumer。可以在常规阶段异步提交，在Consumer关闭前，使用同步提交。也可以分批提交，维护一个计数器，没消费一定数量的消息，就提交一次。

##### Consumer 异常
当消费者消费消息超时后，再次拉取消息，会报异常，解决的办法有:
- 缩短单条消息处理的时间。
- 增加消费最大时长 max.poll.interval.ms， 默认 5 分钟
- 减少一次性消费的消息总数 max.poll.records， 默认 500 条
- 使用多线程加速消费

##### kafka 高性能的原因
- 服务端：
  - 文件分段，顺序读写IO
  - 批处理，压缩
- 客户端：
  - pagecache 读数据
  - 零拷贝
- 利用 pagecache 加速消息读写，PageCache 就是操作系统在内存中给磁盘上的文件建立的缓存。大部分情况下，消费读消息都会命中 PageCache，带来的好处有两个：一个是读取的速度会非常快，另外一个是，给写入消息让出磁盘的 IO 资源，间接也提升了写入的性能。
- 零拷贝技术：直接从 PageCache 中把数据复制到 Socket 缓冲区，由于不用把数据复制到用户内存空间，DMA 控制器可以直接完成数据复制，不需要 CPU 参与，速度更快。

##### 其他
- kafka 保证已提交的数据不会丢失，何为“已提交”，可以配置为所有broker写入日志或有一个broker写入日志就认为"已提交"
- 一个 Consumer Group 可以订阅多个 Topic， 一个 Consumer Group 下的 Consumer 数量应该小于等于它订阅的所有Topic 的分区总和，多余的 Consumer 会一致空闲

# rabbitmq
一个队列可以被多个消费者轮询的方式消费，而kafka一个分区只能被一个消费者消费
#### 交换器
相关术语：
- RoutingKey：路由键。生产者将消息发送给交换器的时候，一般会指定一个 RoutingKey， 用来指定这个消息的路由规则，RoutingKey 需要与交换器类型和 BindingKey 联合使用才能生效
- Binding: 绑定。将交换器与与队列关联起来。在绑定的时候指定一个 BindingKey 就可以知道将消息路由到那个队列；一个队列可以有多个BindingKey；BindingKey与交换器类型有关，比如 fanout 类型的交换器会无视 BindingKey
- 生产者将消息发送到交换器时，需要一个 RoutingKey， 当BindingKey 与 RoutingKey 相匹配时，消息就会被路由到对应的队列中。

类型：
- fanout：会把发送到给交换器的消息发送到所有与该交换器绑定的队列
- direct：把消息路由到 BindingKey 与 RoutingKey 完全匹配的队列
- topic: BindingKey 可以模糊匹配 Routing， `*`表示匹配一个单词，`#`表示匹配0个或多个单词；
- headers: 不依赖 BindingKey， 依赖消息自定义的 header，性能差没人用


#### 死信队列 DLX(Dead Letter Exchange)
当消息在一个队列中变成死信时，它能被发送一个死信队列中，进行后续操作。  
消息会变成死信的情况：  
- 消息被拒绝(Basic.Reject/Basic.Nack), 并且 requeue 参数为 false
- 消息过期
- 队列达到最大长度  


死信队列配合 TTL 还可以实现延迟队列。
#### 延迟队列
应用场景：  
- 订单支付超时，更新为异常订单。
- 定时电饭煲  

生产者为消息设定过期时间并指定死信队列，消费者监听死信队列

#### 优先队列
设置队列的 `x-max-priority` 参数。   

如果消费者消费速度大于生产速度，设置优先级并不会有什么作用。

#### 消息确认
- 消费者确认：
- 生产者确认：

#### 持久化
- 交换器持久化：如果交换器没有持久化，当 broker 重启后，交换器的元数据会丢失，但消息数据不会丢失，只是不能将消息发送到这个交换器了。
- 队列持久化：声明队列时， 将 `durable` 设置为 true。如果不持久化，broker 重启后，队列和数据都会丢失
- 消息持久化：设置deliveryMode为2

#### 其他
- rabbitmq broker 不会为消息设置过期时间，判断消息是否需要重新投递的唯一依据是消费者连接是否已经断开。这么设计的原因是，rabbitmq 允许消费者消费一条消息很久很久。


# queue
##### 为什么需要消息队列
- 异步处理：可以更快的返回结果，同步流程改为并发流程
- 流量控制：削峰填谷。隔离网关和后端服务，达到流量控制和保护后端服务的目的。更直接的控制流量，可以根据处理请求的能力，使用消息队列维护一个令牌桶。
- 服务解耦：下游系统通过订阅模式，订阅上游系统的数据变化
- - 数据驱动的任务依赖
- - 上游不关心多下游执行结果

##### 消息队列引起的问题
- 延迟
- 系统复杂度
- 数据不一致

##### rabbimq
优点:  
- 轻量
- 使用广泛
- 支持负责路由  


缺点:  
- 对消息堆积支持不好。大量消息积压会导致其性能急剧下降
- 性能一般，每秒几万到十几万

##### RocketMQ (消息模型与kafka一致)
优点:  
- 阿里双十一
- Java，国人开发
- 比 rabbit 性能高一个量级，每秒几十万消息

缺点：  
- 国产，与周边生态集成和兼容程度略逊

##### kafka
优点: 
- 与周边生态兼容性最好，尤其在大数据领域
- 性能优秀，与RocketMQ同档
- 在开启压缩的情况下，极限处理能力非常大

缺点:
- 异步批量的设计，使响应时延比较高。客户端发送一条消息，kafka并不会立即发出去，而是攒一会儿一起发送
- 消息数不多的时候，不适合用。不太适合在线业务场景

##### 保证数据不丢失
检查消息丢失:   
利用消息队列的有序性验证消息是否丢失。Producer端，每发出的消息附加一个连续递增的序号，Consumer 端检查这个序号的连续性。可以利用`拦截器`将序号注入到消息中，Consumer 收到消息拦截器中检测序号的连续性，这样就不会进入业务代码。

生产阶段：  
 通过请求确认机制保证消息可靠传输。只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。超时重试或返回异常。
 
存储阶段：
单节点 Broker，要将消息写入磁盘再给 Producer 返回确认响应；  
Broker集群，要将消息发送到2个以上的节点，再给客户端返回确认响应。  

消费阶段：  
消费成功后，才给 Broker 发送确认响应。消费不成功，重试

##### 处理消息重复(幂等)
`At least once + 幂等消费 = Exactly once`
- 利用数据库唯一约束实现幂等、或 redis 的 setnx
- 为更新的数据设置前置条件，或给数据设置版本号，当数据的版本号与消息中的版本号一直，才可以消费消息
- 记录并检查操作。给每条消息指定一个全局唯一的id,消费时，根据这个ID检查这条消息是否被消费过。

##### 消息积压
- 设计的时候，要保证消费端的消费性能有奥高于生产端的发送性能。  
- 增加消费者，同时也要扩容分区，因为一个分区只能被一个消费者消费，
- 监控是生产变快了，还是消费变慢了。系统降级，减少发送方发送的数据，保障重要业务
- 注意排查是不是消费失败导致一条消息返回消费
