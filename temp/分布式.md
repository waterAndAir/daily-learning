#### 拜占庭将军问题
几个将军联合作战时，统一作战方案的问题。
- 将军：节点
- 忠将：正常节点
- 叛将：故障节点
- 信使：通信
- 信使被间谍替换：通讯劫持

解决方案：
- 口信消息：要保证将军总数不小于 3m+1， m表示叛将的数量
- 消息签名

分布式系统中，大部分不考虑间谍，可以使用非拜占庭容错算法，比如raft，paxos，zab；如果考虑间谍，就要使用拜占庭容错算法，比如应用于区块链中的共识算法。

#### Bully 算法，基于序号

- 节点ID最大的无条件成为 Leader
- 优点：容易理解，选举速度快，算法复杂度低，易于实现
- 缺点：信息存储量大，加节点易频繁切主，
- 适用于小规模场景，如MongoDB 的副本集故障转移


#### Raft 民主投票，少数服从多数
- 少数服从多数
- 优点: 选举速度快，算法复杂度低，易于实现
- 缺点：要求系统全连接，消息通信量大，不适合大规模集群，稳定性比 Bully 好
- 适用于中小规模，如 k8s，etcd


#### ZAB 算法，具有优先级的民主投票
- 倾向于让数据最新，或ID最大的节点成为 Leader
- 优点：性能高，对系统无特殊要求
- 缺点：选举时间长，复杂度高
- 适用于大规模分布式场景，如 zookeeper

### 分布式事务
事务的ACID特性：
- 原子性
- 一致性完整性
- 隔离性
- 持久性

分布式事务的 BASE 特性：
- 基本可用，损失一点可用性
- 柔性状态，允许短暂的延迟
- 最终一致

有三种方法：
- 基于 XA 协议的二阶段提交协议
- 三阶段提交协议方法
- TCC （try confirm cancel）也属于两阶段提交，是一种补偿方式

分布式中 ACID 过于苛刻，选择 BASE，它是 AP 的延伸

#### 基于 XA 协议的二阶段提交法（类似于集中式的方法）
- XA 规定了事务管理器（协调者）和资源管理器（参与者，通常由数据库实现）
- 二阶段提交协议用于保证一致性

##### 过程
投票阶段（CanCommit）：
1. 协调者向参与者发起 CanCommit 请求并等待响应
2. 参与者执行操作并记录日志
3. 参与者执行成功返回 Yes， 失败返回 No

提交阶段（DoCommit）：
1. 若协调者收到 Yes， 则向参与者发送 DoCommit 消息，参与者完成操作后返回 HaveCommitted 消息
2. 若协调者收到 No，则向参与者发送 DoAbort 消息，此时，发送 Yes 的参与者会根据日志回滚，所有参与者向协调者发送 HaveCommited
3. 协调者收到 HaveCommited，事务结束


##### 不足
- 同步阻塞：当本地资源管理器占用资源时，其他资源管理器访问同一资源会阻塞
- 单点故障：事务管理器（协调者）是单点
- 数据不一致：网络问题导致的消息不能正常传达，引起数据不一致

https://mp.weixin.qq.com/s/Ee9FkPcpZ2Hc3-oG559nEw
#### TCC(try confirm cancel) 均由业务代码实现
提现冻结金额(负责资源的检查和预留)，解冻资金(cancel，预留资源的取消，使资源回到初始状态) ,提交资金(confirm)  

##### TCC注意点
###### 空回滚： Try未执行，Cancel 先执行了，网络不好，提现操作表，就是这里说的事务表
需要一张额外的事务控制表，其中有分布式事务 ID 和分支事务 ID，第一阶段 Try 方法里会插入一条记录，表示一阶段执行了。Cancel 接口里读取该记录，如果该记录存在，则正常回滚；如果该记录不存在，则是空回滚。
###### Commit 和 Cancel 要保证幂等
记录每个分支事务的执行状态。在执行前状态，如果已执行，那就不再执行；否则，正常执行。
###### 防悬挂，业务预留资源后没有处理，cancel 先空回滚了，才执行 Try
还是记录事务表，在执行 Try 的时候查一下有没有被cancel，如果没有cancel，就执行 Try，如果cancel，就不执行

#### 三阶段提交协议法

解决二阶段的同步阻塞和数据不一致，引入超时和准备阶段

##### 过程
CanCommit 阶段：同二阶段提交 CanCommit 阶段   

PreCommit 阶段：
1. 如果所有参与者回复都是 Yes，协调者会进行预执行：向参与者发送 PreCommit，进入预提交阶段；参与者执行操作，记录 Undo，Redo 日志；响应 ACK。 
2. 有参与者返回 No，或有超时：向参与者发送 Abort 中断操作；参与者中断事务

DoCommit 阶段：
- 执行提交：协调者发送 DoCommit，进入提交状态；参与者正式提交事务；响应 ACK；协调者接收到所有 ACK，完成事务。如果参与者长时间没有收到 ACK，会自动提交。不会阻塞
- 中断阶段：协调者发送 Abort；参与者接收到 Abort，利用 Undo 日志回滚操作。响应 ACK；协调者接收到所有 ACK 后结束事务。


#### 基于分布式消息的最终一致性法

kafka + mysql + rabbitmq：先将消息持久化，在通过业务规则进行失败重试

#### 不严格的分布式事务方案
- 补偿事务，通过代码ifelse实现，缺点是没有考虑不到 rollback 失败的情况；不具备通用性
- 后置提交优化；优点是缩短了可能出现不一致的时间段，缺点是阻塞的时间长。


### 分布式锁


#### 基于数据库
- 创建一张锁表，对林捷资源做唯一约束；要锁住资源时就加一条记录，释放锁时删除记录
- 优点：容易理解
- 缺点：单点故障；死锁；实现复杂；性能低；可靠性低
- 适用于并发量低，性能要求低的场景

#### 基于 redis
- setnx 实现
- 性能高；可以跨集群；无单点故障；易于实现
- 缺点：锁失效时间控制不稳定；可靠性不如 zookeeper；不易理解。
- 适用于高并发，对性能要求高的场景

```
set lock_name true ex 10 nx
...
del lock_name
```
```
EX seconds – 设置过期时间，单位秒
PX milliseconds – 设置过期时间，单位毫秒
NX – key 不存在才设置 key 的值
XX – key 已经存在才可以设置 key 的值
```
超时问题：  
- 不要执行过长的任务。给 value 设置随机值，使用lua语言在执行 del 前先判断value是否一致。

锁冲突：
- 抛出异常，由客户端决定是否重连  
- 把冲突的请求的消息加入另一个队列，另做处理

#### 基于 zookeeper 
- 在对应的持久节点目录下为每个进程创建一个临时顺序节点，每个节点确定的编号是否最小，若最小，则获得锁，否则等待小编号节点释放锁
- 优点：无单点，不可重入，死锁等问题；几乎解决了数据库和redis的不足；可靠性高，易于实现。
- 缺点：性能没有redis高
- 适用于大部分场景，不适用于性能要求极高的场景

## 分布式通信
### RPC 调用

### Pub/Sub 发布订阅

### Point To Point 点对点
## 分布式存储
### CAP（Consistency 一致性，Availability 可用性，Partition Tolerance 分区容错性）
分布式系统中，如果不能保证 P, CA 也是无法同时保证的

- 服务注册：zookeeper CP， Eureka AP, bilibili discovery AP
- 分布式锁： 基于mysql，单点不属于cap范畴；基于 redis，AP;基于 zookeeper， CP
- 分布式事务: CAP 理论不适用，进而出现BASE理论；牺牲一点一致性，保证可用性，保证最终一致；分布式事务都遵循 BASE 理论
  - 两阶段事务 2PC：
  - 补偿事务 TCC：
  - 本地消息: 就是异步队列
  - MQ 事务消息: RocketMQ,Kafka的事务，要有一个记录事务的表，记录事务ID，事务状态
#### 保CA弃P （分布式系统必须保证P）
- 特点：牺牲分区容错性，相当于放弃使用分布式系统
- 场景：单点系统：DBMS

#### 保CP弃A
- 特点：发生网络分区后，部分节点不可用，当数据达到最终一致后，再次可用
- 场景：Zookeeper， Redis，Hbase

#### 保AP弃C
- 特点：发生网络分区后，为了保证高可用，需要立刻响应用户请求
- 场景：Eureka，Cassandra


### 分布式数据分布

#### 考虑的维度
- 数据均匀：不同节点的数据存储和用户访问要均匀
- 数据稳定：节点数量发生变化时，要尽量少的进行数据迁移
- 节点异构性：考虑每个节点的不同性能
- 隔离故障域：数据尽量放到不同机房机架，保证可靠性
- 性能稳定性：不能因为节点数据变化，造成读写速度变慢

#### 哈希
- 根据 key 值，通过hash函数算出对应的节点
- 哈希函数得当，有不错的均匀性；稳定性差
- 适用于同类型节点且节点数量固定的场景。Redis

#### 一致性哈希
- 将存储节点和数据都映射到一个首尾相接的哈希环上，存储节点可以根据 IP 地址进行哈希，数据通常经过顺时针方向寻找自己所属的节点
- 优缺点：保证了数据稳定，但均匀性问题比较明显，加入节点后，后继节点的负载会变大
- 适合同类型节点，节点规模会发生变化的场景 Cassandra

#### 带有限负载的一致性哈希
- 给每个存储节点设置一个存储上限，控制存储节点添加或移除造成的数据不均匀问题
- 优缺点：均匀性和稳定性提升，但没有考虑节点异构问题，没有完全做到数据的均匀分布
- 适合同类型节点，节点规模会发生变化的场景

#### 带虚拟节点的一致性哈希
- 根据每个节点的性能，为每个节点划分不同数量的虚拟节点，并将这些虚拟节点映射到哈希环中，再按照一致性哈希算法进行数据映射和存储
- 优缺点：解决了节点异构性问题，数据均匀性和稳定性也得到了提升
- 适合异构节点，节点规模会发生变化的场景，Memcached

### 数据复制
- 同步复制
- 异步复制
- 半同步复制：等待其他一个或一半以上节点复制成功


## 分布式高可靠
### 负载均衡
- 轮询
- 加权轮询
- 随机
- 加权随机
- 哈希和一致性哈希

### 流量控制
- 滑动窗口：在一定时间内仅允许一定数量的请求，可以通过 redis 的zset实现。问题: 如果定60s不超过10个请求，name如果 1s 就有10 个请求，那么后面 59s 都会访问失败。
- 令牌桶策略：生成速率一定，消耗速度可变，每个请求先获取令牌，适用于突发的要求及时响应的场景
- 漏斗：消费速率一定，生成速率可变，超过漏斗的请求丢弃。适用于间隔性突发流量

### 故障隔离
- 线程隔离
- 进程隔离
- 资源隔离

### 故障恢复
- 主备切换
- master 选举，AP 或 CP

#### 网络分区问题
集中式:主备切换
分集中式：根据规则选出一个分区，比如选出节点最多的，票数最高的

#### 对比单体和微服务
#####  单体的缺点
user 表用户数据为例
- 代码到处拷贝：每个业务都通过手写sql获取user数据
- 复杂性扩散：加缓存到处加；分库分表到处处理判断；一种bug，到处改
- 库的复用和耦合：为了减少拷贝代码，可能会想到抽象出统一的库。这样可以解决上面两个问题，但是库的版本维护会导致业务之间的耦合
- sql 质量：sql可能来自于任何一个人
- db 耦合：大量join

##### 服务化的好处
引入 user-service 层
- 调用方方便，不需要考虑sql
- sql 质量可以专注保证
- 防止代码拷贝
- 屏蔽底层复杂度：缓存，分库分表，扩容
- 专门的性能优化