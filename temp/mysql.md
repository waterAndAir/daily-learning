
## 锁
### myisam 表锁
- 共享读锁: 不会阻塞其他读请求，但会阻塞写请求
- 独占写锁: 阻塞读写请求
- myisam 自动给语句加表锁。串行，不会发生死锁

### innodb
##### 共享/排它锁(Shared and Exclusive Locks)
读并发，写阻塞

##### 自增锁(表锁)
自增锁是一种特殊的表级别锁（table-level lock），专门针对事务插入AUTO_INCREMENT类型的列。最简单的情况，如果一个事务正在往表中插入记录，所有其他事务的插入必须等待，以便第一个事务插入的行，是连续的主键值。

##### 意向锁(Intention Locks)(表锁)

意向锁是指，未来的某个时刻，事务可能要加共享/排它锁了，先提前声明一个意向。

- 意向共享锁(intention shared lock, IS)，它预示着，事务有意向对表中的某些行加共享S锁： lock in share mode 
- 意向排它锁(intention exclusive lock, IX)，它预示着，事务有意向对表中的某些行加排它X锁: for update  

用 select… in share mode 获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行 update 或者 delete 操作。
但是如果当前事务也需要对该记录进行更新操作,则有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用 select… for update 方式获得排他锁。  

- 注意意向锁是自动加的

意向锁是有数据引擎自己维护的，用户无法手动操作意向锁，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。

##### 插入意向锁（是间隙锁的一种）
多个事务，在同一个索引，同一个范围区间插入记录时，如果插入的位置不冲突，不会阻塞彼此。 

- 提高了并发出入的效率  

##### 记录锁 record-lock (唯一索引等值查询)
记录锁，它封锁索引记录，例如：
```
select * from t where id=1 for update;
```
需要说明的是：
```
select * from t where id=1;
```
则是快照读(SnapShot Read)，它并不加锁；

##### 间隙锁 gap-lock (唯一索引范围查询)
间隙锁，它封锁索引记录中的间隔，或者第一条索引记录之前的范围，又或者最后一条索引记录之后的范围。
```
select * from t where id between 8 and 15 for update;
```

- 间隙锁的主要目的，就是为了防止其他事务在间隔中插入数据，以导致“不可重复读”。
- 如果把事务的隔离级别降级为读提交(Read Committed, RC)，间隙锁则会自动失效。

##### 临键锁(Next-Key Locks) 对于行的查询大多是这种锁 
是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。
如果一个会话占有了索引记录R的共享/排他锁，其他会话不能立刻在R之前的区间插入新的索引记录。

临键锁的主要目的，也是为了避免幻读(Phantom Read)。如果把事务的隔离级别降级为RC，临键锁则也会失效。

查询的索引具有唯一性的时候，会退化为记录锁。否则，会将自己这一行和前后的区间锁起来，防止幻读


##### 注意
- 意向锁自动加，select 不自动加锁。  
- 对没有使用索引的查询语句加锁，会对全部记录加锁，相当于表锁，因为行锁是对索引加锁。
- 因为是对索引加锁，所以如果两行记录使用了相同的索引，也会造成锁等待
- 如果事务中需要锁多个行，要把最可能造成冲突，最可能影响并发度的锁尽量往后放，这样可以最大程度的减少事务之间的锁等待。

#### innodb 表锁
应用场景：
- 事务中需要更新大部分或全部行
- 事务涉及多个表，很可能死锁

注意：
- lock tables 表锁是由 mysql server 管理的，不是innodb管理的，要将 autocommit 设为 0，必须用 unlock tables 释放表锁

### 死锁
#### 场景
两个事务都需要获得对方持有的排他锁才能继续完成事务。
1. session1对表a中id为1的行加排它锁
2. session2对表b中id为1的行加排它锁
3. session1尝试获取表b中id为1的行的排它锁形成阻塞
4. session2尝试获取表a中id=1的排它锁，发生死锁。

#### 避免死锁
- 如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会，确保事务之间的等待不会出现环。。
- 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；
- 非常容易产生死锁的业务，使用表锁减少死锁产生
- 尝试分布式锁或乐观锁
- 超时混回滚
- 检测死锁，当事务依赖形成环状，就认为发生了死锁，这时选择其中一个影响最小的事务进行回滚

## MVCC 多版本并发控制
##### 解决并发的思路:
- 普通锁：串行，很慢
- 读写锁：读并发，写串行，快了一点
- MVCC: 读写都实现了并发

##### MVCC：
- 在写的时候，将数据复制一份，以版本号区分，写操作复制的数据，读操作读旧版本的数据。  
- mysql 通过 undolog(写操作维护版本) 和 readview(读操作直接快照读) 实现 MVCC。

## 事务
### 事务的特征 ACID
- 原子性（Atomicity），即事务最终的状态只有两种，全部执行成功和全部不执行。若处理事务的任何一项操作不成功，就会导致整个事务失败。一旦操作失败，所有操作都会被取消（即回滚），使得事务仿佛没有被执行过一样。
- 一致性（Consistency），是指事务操作前和操作后，数据的完整性保持一致或满足完整性约束。比如，用户 A 和用户 B 在银行分别有 800 元和 600 元，总共 1400 元，用户 A 给用户 B 转账 200 元，分为两个步骤，从 A 的账户扣除 200 元和对 B 的账户增加 200 元 ; 一致性就是要求上述步骤操作后，最后的结果是用户 A 还有 600 元，用户 B 有 800 元，总共 1400 元，而不会出现用户 A 扣除了 200 元，但用户 B 未增加的情况 (该情况，用户 A 和 B 均为 600 元，总共 1200 元)。
- 隔离性（Isolation），是指当系统内有多个事务并发执行时，多个事务不会相互干扰，即一个事务内部的操作及使用的数据，对其他并发事务是隔离的。
- 持久性（Durability），也被称为永久性，是指一个事务完成了，那么它对数据库所做的更新就被永久保存下来了。即使发生系统崩溃或宕机等故障，只要数据库能够重新被访问，那么一定能够将其恢复到事务完成时的状态。


其中一致性是强一致性，在分布式中，有BASE理论用最终一致性实现分布式事务的一致性。

### 事务是怎么实现的？
- 原子性：undolog
- 持久性: redolog + binlog
- 隔离性: 锁 + MVCC = 不同的隔离级别
- 一致性: 由前三项保证，通过回滚，以及恢复，和在并发环境下的隔离做到一致性。

### 隔离级别及其实现

隔离级别 | 实现方式 | 存在的问题
---|--- | ---
读未提交 | 不加锁 | 脏读，读出了未提交事务的修改
读已提交 | 普通读是快照读。写操作加排它锁。加锁的读，除了检查外键和唯一键，其他只加记录锁；事务在每次Read操作时，都会建立Read View | 不可重复读
可重复读 | 普通读 MVCC 快照读。加锁读 record-lock 、gap-lock、next-key-lock；事务在`第一个Read`操作时，会建立Read View  | 幻读(gap-lock,next-key-lock 解决幻读)
序列化   | 给所有的读都隐式加 lock in share mode | -


更新丢失的问题: 用锁



## 索引
### 索引类型
#### 物理角度
- 聚簇索引
- 非聚簇索引

#### 数据结构角度
- Hash 索引
- B+ 树索引
- fulltext 索引
#### 逻辑角度
- 主键索引
- 唯一索引
- 普通索引
- 联合索引
- 全文索引

### 注意点
- 索引并不是越多越好，要根据查询有针对性的创建，考虑在WHERE和ORDER BY命令上涉及的列建立索引，可根据EXPLAIN来查看是否用了索引还是全表扫描；
- 应尽量避免在WHERE子句中对字段进行NULL值判断，否则将导致引擎放弃使用索引而进行全表扫描；
- 值分布很稀少的字段不适合建索引，例如“性别”这种只有两三个值的字段；
- 字符字段只建前缀索引；
- 字符字段最好不要做主键；
- 不用外键，由程序保证约束；
- 尽量不用UNIQUE，由程序保证约束；
- 使用多列索引时主意顺序和查询条件保持一致，同时删除不必要的单列索引。
- 对索引字段做函数操作，会破坏索引值的有有序性，致使优化器放弃走索引
- 索引字段上的隐式类型转换和隐式字符编码转换，会被mysql在字段上执行函数操作，导致放弃索引

##### 为什么唯一索引插入速度比普通索引慢？
唯一索引的插入不能使用 CacheBuffer
##### 为什么唯一索引查询速度比普通索引快
唯一索引查到一条记录直接返回，不用检查下一条
##### 为什么使用联合索引
减少开销，方便使用覆盖索引，效率高（查询条件多，返回的行就少）

##### sql为什么慢？
偶尔慢：
- 数据库在刷新脏页，将 redolog 刷到同步到磁盘
- 拿不到锁

一直慢：
- 没建立或没用到索引
- 数据库选错了索引

### B+树
#### 为什么数据库使用 b+ 树
- 树形结构插入和查询速度都快，也适合做范围查询，在b数的基础上在叶子节点之间加入了链表，进一步优化了范围查询
- 多叉树可以减少磁盘访问次数，每层节点 1000， 4层就可上亿
- 叶子节点相对紧密，适合磁盘存储；非叶子节点不存实际数据，适合内存存储；这样可以加速查询。
- 为避免删除导致出现大量节点数较少的节点，规定子节点数少于 m/2 就与相邻的节点合并，大于 m，就分裂



##### 数据迁移的思路
- 停机迁移
- 异步追日志: 比如将修改发到kafka，新存储服务，读取kafka，保持与旧库异步更新
- 双写

##### 双写迁移流程
1. 同步程序从旧库中复制到新库
2. 上线双写服务，只读写旧库
3. 开启双写，停止同步程序
4. 开启对比补偿程序
5. 逐步将读请求迁移到新库上
6. 停止补偿程序，关闭双写，读写都切换到新库
7. 下线旧库和双写，该单写



#### 索引相关
##### 负向条件查询不能使用索引。
select * from order where status!=0 and stauts!=1
not in/not exists都不是好习惯。

可以优化为in查询：
select * from order where status in(2,3)

##### 前导模糊查询不能使用索引。
select * from order where desc like '%XX'
而非前导模糊查询则可以：
select * from order where desc like 'XX%'

##### 数据区分度不大的字段不宜使用索引。
select * from user where sex=1
原因：性别只有男，女，每次过滤掉的数据很少，不宜使用索引。

经验上，能过滤80%数据时就可以使用索引。对于订单状态，如果状态值很少，不宜使用索引，如果状态值很多，能够过滤大量数据，则应该建立索引。

##### 在属性上进行计算不能命中索引。
select * from order where YEAR(date) < = '2020'
即使date上建立了索引，也会全表扫描，可优化为值计算：
select * from order where date < = CURDATE()
或者：
select * from order where date < = '2020-01-01'
##### 如果业务大部分是单条查询，使用Hash索引性能更好，例如用户中心。
select * from user where uid=?
select * from user where login_name=?
原因：
B-Tree索引的时间复杂度是O(log(n))；
Hash索引的时间复杂度是O(1)。
##### 允许为null的列，查询有潜在大坑。
单列索引不存null值，复合索引不存全为null的值，如果列允许为null，可能会得到“不符合预期”的结果集。
select * from user where name != 'shenjian'
如果name允许为null，索引不存储null值，结果集中不会包含这些记录。

##### 复合索引最左前缀，并不是指SQL语句的where顺序要和复合索引一致。
用户中心建立了(login_name, passwd)的复合索引
select * from user where login_name=? and passwd=?
select * from user where passwd=? and login_name=?
都能够命中索引。
 
select * from user where login_name=?
也能命中索引，满足复合索引最左前缀。
 
select * from user where passwd=?
不能命中索引，不满足复合索引最左前缀。

##### 
#### 其他

##### 如果明确知道只有一条结果返回，limit 1能够提高效率。
select * from user where login_name=?
可以优化为：
select * from user where login_name=? limit 1
原因：
你知道只有一条结果，但数据库并不知道，明确告诉它，让它主动停止游标移动。

##### 其他
- 应尽量避免在 where 子句中使用!=或<>操作符，否则将引擎放弃使用索引而进行全表扫描。
- 对查询进行优化，应尽量避免全表扫描，首先应考虑在 where 及 order by 涉及的列上建立索引。
- 应尽量避免在 where 子句中对字段进行 null 值判断，否则将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num is null
- 可以在num上设置默认值0，确保表中num列没有null值，然后这样查询：select id from t where num=0
- 尽量避免在 where 子句中使用 or 来连接条件，否则将导致引擎放弃使用索引而进行全表扫描，如：select id from t where num=10 or num=20 可以这样查询：select id from t where num=10 union all select id from t where num=20
- 下面的查询也将导致全表扫描：(不能前置百分号)select id from t where name like ‘%c%’ 若要提高效率，可以考虑全文检索。
- in 和 not in 也要慎用，否则会导致全表扫描，如：select id from t where num in(1,2,3) 对于连续的数值，能用 between 就不要用 in 了：select id from t where num between 1 and 3
- 如果在 where 子句中使用参数，也会导致全表扫描。select id from t where num=@num 可以改为强制查询使用索引：select id from t with(index(索引名)) where num=@num
- 应尽量避免在 where 子句中对字段进行表达式操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where num/2=100 应改为: select id from t where num=100*2
- 应尽量避免在where子句中对字段进行函数操作，这将导致引擎放弃使用索引而进行全表扫描。如：select id from t where substring(name,1,3)=’abc’ –name以abc开头的id select id from t where datediff(day,createdate,’2005-11-30′)=0 –’2005-11-30′生成的id
应改为:
select id from t where name like ‘abc%’
select id from t where createdate>=’2005-11-30′ and createdate<’2005-12-1′
- 不要在 where 子句中的“=”左边进行函数、算术运算或其他表达式运算，否则系统将可能无法正确使用索引。
- 在使用索引字段作为条件时，如果该索引是复合索引，那么必须使用到该索引中的第一个字段作为条件时才能保证系统使用该索引，否则该索引将不会被使 用，并且应尽可能的让字段顺序与索引顺序相一致。

- 不要写一些没有意义的查询，如需要生成一个空表结构：

select col1,col2 into #t from t where 1=0

这类代码不会返回任何结果集，但是会消耗系统资源的，应改成这样：

create table #t(…)

- 很多时候用 exists 代替 in 是一个好的选择：

select num from a where num in(select num from b)

用下面的语句替换：

select num from a where exists(select 1 from b where num=a.num)

- 并不是所有索引对查询都有效，SQL是根据表中数据来进行查询优化的，当索引列有大量数据重复时，SQL查询可能不会去利用索引，如一表中有字段 sex，male、female几乎各一半，那么即使在sex上建了索引也对查询效率起不了作用。

- 索引并不是越多越好，索引固然可以提高相应的 select 的效率，但同时也降低了 insert 及 update 的效率，因为 insert 或 update 时有可能会重建索引，所以怎样建索引需要慎重考虑，视具体情况而定。一个表的索引数较好不要超过6个，若太多则应考虑一些不常使用到的列上建的索引是否有 必要。

- 应尽可能的避免更新 clustered 索引数据列，因为 clustered 索引数据列的顺序就是表记录的物理存储顺序，一旦该列值改变将导致整个表记录的顺序的调整，会耗费相当大的资源。若应用系统需要频繁更新 clustered 索引数据列，那么需要考虑是否应将该索引建为 clustered 索引。

- 尽量使用数字型字段，若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。

- 尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。

- 任何地方都不要使用 select * from t ，用具体的字段列表代替“*”，不要返回用不到的任何字段。

- 尽量使用表变量来代替临时表。如果表变量包含大量数据，请注意索引非常有限（只有主键索引）。

- 避免频繁创建和删除临时表，以减少系统表资源的消耗。

- 临时表并不是不可使用，适当地使用它们可以使某些例程更有效，例如，当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件，较好使 用导出表。

- 在新建临时表时，如果一次性插入数据量很大，那么可以使用 select into 代替 create table，避免造成大量 log ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先create table，然后insert。

- 如果使用到了临时表，在存储过程的最后务必将所有的临时表显式删除，先 truncate table ，然后 drop table ，这样可以避免系统表的较长时间锁定。

- 尽量避免使用游标，因为游标的效率较差，如果游标操作的数据超过1万行，那么就应该考虑改写。

- 使用基于游标的方法或临时表方法之前，应先寻找基于集的解决方案来解决问题，基于集的方法通常更有效。

- 与临时表一样，游标并不是不可使用。对小型数据集使用 FAST_FORWARD 游标通常要优于其他逐行处理方法，尤其是在必须引用几个表才能获得所需的数据时。在结果集中包括“合计”的例程通常要比使用游标执行的速度快。如果开发时 间允许，基于游标的方法和基于集的方法都可以尝试一下，看哪一种方法的效果更好。

- 在所有的存储过程和触发器的开始处设置 SET NOCOUNT ON ，在结束时设置 SET NOCOUNT OFF 。无需在执行存储过程和触发器的每个语句后向客户端发送 DONEINPROC 消息。

- 尽量避免向客户端返回大数据量，若数据量过大，应该考虑相应需求是否合理。

- 尽量避免大事务操作，提高系统并发能力


#### 如何减少 mysql CPU 消耗
CPU 消耗 = us(用户) + wa(IO等待,空闲) + sy(系统) + ni&si(软硬中断) + id(空闲)    
后三项较难改变  

- 减少计算: mysql 避免使用函数；减少排序；禁止类型转换；简单类型
- 减少逻辑IO：优化索引；合理拆表；合理使用足够容量的数据类型
- 减少 query 量: 适当缓存；
- 升级 CPU: 低延迟的升级CPU处理速度；高吞吐的增加CPU数量



### 种类
- 错误日志
- 查询日志
- 慢查询日志
- binlog （server 层）
- 中继日志 relay log
- wal 的 redo log （innodb 引擎层）


##### redo log(innodb 特有)
重做日志，两部分组成，重做日志缓冲(redolog buffer)和重做日志文件(redolog file)；
- 通过顺序写替代随机写，提高IO能力，提高并发
- 为了在实行事务时断电后恢复事务
- 记录物理变化

使用 WAL(write ahead log) 机制，先将写操作记录到 redo log 并更新内存，再在系统空闲时将操作记录更新到磁盘。 Redo log 是固定大小的循环数组，在它上面维护了两个变量，check_point 和 write_pos：

check_point 表示已经同步到磁盘的位置，向后推移
write_pos 表示已经日志记录的当前位置，向后推移
如果 write_pos 追上了 check_point 就表示 redo log 满了，需要立即执行同步磁盘的操作推进 check_point

因为有了 Redo log， 所以 mysql 在意外宕机后，之前提交的记录都不会丢失。

##### undolog
- 记录逻辑变化
- 用于回滚未提交的事务


##### Innodb 更新数据使用 redolog 和 binlog 的两阶段提交：
- 执行器通过引擎将数据读入内存
- 执行器执行修改数据操作，并调用引擎的写数据接口
- 引擎将新数据更新到内存中，同时将更新操作记录到 redo log 中，此时 redo log 处于 prepare 状态。告知执行器执行完成，可以提交事务。
- 执行器生成这个操作的 binlog， 并将 binlog 写入磁盘
执行器调用引擎提交事务接口，引擎将 redo log 的状态改为 commit 状态，更新完成。
- 两阶段提交可以保证 redo log 和 binlog 逻辑上的一致

#### 存储引擎

项目 | Innodb | Myisam |
---|---| ---
事务 | 是 | 否
锁| 行级锁|表级锁
特点| - | 读速度快


##### Mysql 自增ID的单调性和连续性
- 单调性，mysql 之前是通过内存中维护自增ID,重启后查表最大ID实现单调性，但在删除行的情况下，可能有问题；现在将自增ID记录到 redo log 中，保证了单调性
- 连续性，并发事务出现 rollback后，会出现自增ID不连续的情况；通过事务隔离级别为序列化的方式，可以解决，但是没必要。



##### msyql 大表修改表结构，使用 `pt-online-schema-change`
原理：
- 第一步，先创建一个扩充字段后的新表
- 在原表user上创建三个触发器，对原表user进行的所有insert/delete/update操作，都会对新表user_new进行相同的操作；
- 分批将原表user中的数据insert到新表user_new，直至数据迁移完成；
- 删掉触发器，把原表移走（默认是drop掉）；
- 把新表user_new重命名（rename）成原表user；



##### 消息顺序性怎么保证？
- 考虑以客户端时间为准还是服务端时间为准
- 性能要求不高可以使用单点 写db的seq/auto_inc_id
- 考虑业务能不能接受误差不大的趋势递增id，如果能，使用分布式ID
- 单点序列化，比如 mysql 主从复制
- 客户端为准设置 seq或时间，可能导致接受方 先收到 msg3，然后收到 msg2 放到了 msg3 前面
- 服务端为准，可能导致接收方先收到 msg3， 再收到 msg2，msg1
- 单对单聊天，只需保证发出的时序与接收的时序一致，可以利用客户端seq；
- 群聊，只需保证所有接收方消息时序一致，需要利用服务端seq，方法有两种，一种单点绝对时序(存在单点)，另一种id串行化(用群id做hash，一个群的消息hash到一个服务器上，用这个服务器上的 seq 保证顺序，可以解决单点问题)；

##### 如何进行容量设计？
- 评估`总访问量`：询问产品、运营；
- 评估`平均访问量`：总量除以总时间，一天算4w秒；
- 评估`高峰QPS`：根据业务曲线图来；
- 评估系统、单机`极限QPS`：压测很重要；
- 根据线上冗余度解题：估计冗余度与线上冗余度差值；

##### 说说负载均衡？
将请求/数据均匀分摊到多个操作单元上执行，其的关键在于均匀：
- 反向代理层的负载均衡，是通过“DNS轮询”实现的
- 站点层的负载均衡，是通过“nginx”实现的
- 服务层的负载均衡，是通过“服务连接池”实现的
- 数据层的负载均衡，要考虑“数据的均衡”与“请求的均衡”两个点，常见的方式有“按照范围水平切分”与“hash水平切分”

##### nginx 反向代理能替代dns？
不能
- nginx， lvs 是单点，不好再进一步提高qps
- 如果有多个异地服务中心，DNS可以根据客户IP就近智能解析

##### 异构网络的负载均衡和过载保护怎么做？
静态权重和动态权重

##### 微信多点登录和消息漫游
- 多端同时收发消息，需要在服务端存同一个用户多个端的登录状态
- 发消息时，要给发送方的多端和接收方的多端都发送消息
- 消息漫游需要把消息都落库，每个客户端需要存一个 last_msg_id

##### 给好友发送离线消息，怎么保证不丢不重？
- 对于同一个用户B，一次性拉取所有用户发给ta的离线消息，再在客户端本地进行发送方分析，相比按照发送方一个个进行消息拉取，能大大减少服务器交互次数；
- 按需拉取，是无线端的常见优化；
- 分页拉取，是一个请求次数与包大小的折衷；
- 应用层的ACK，应用层的去重，才能保证离线消息的不丢不重；
- 下一页的拉取，同时作为上一页的ACK，能够极大减少与服务器的交互次数；

##### 系统通知的设计？
- 对1通知：实时性要求高的，用推模式；实时性要求低的，可以用拉模式
- 对N通知：比如qq登录新闻，用拉模式；实时性要求不高的，用拉模式；实时性要求高的可以用推模式

##### feed 流的推拉实践？
拉模式：  
用户A获取“由别人发布的feed组成的主页”的过程：
1. 获取A的关注列表
2. 获取所关注列表中，所有用户发布的feed
3. 对消息进行rank排序（假设按照发布时间排序），分页取出对应的一页feeds

拉模式（“读扩散”）的优点是：
- 存储结构简单，数据存储量较小，关系数据与feed数据都只存一份
- 关注，取关，发布feed的业务流程非常简单
- 存储结构，业务流程都比较容易理解，适合项目早期用户量、数据量、并发量不大时的快速实现

缺点也显而易见：
- 拉取朋友圈feed流列表的业务流程非常复杂
- 有多次数据访问，并且要进行大量的内存计算，网络传输，性能较低


推模式（写扩散）的优点：
- 消除了拉模式（读扩散）的IO集中点，每个用户都读自己的数据，高并发下锁竞争少
- 拉取朋友圈feed流列表的业务流程异常简单，速度很快
- 拉取朋友圈feed流列表，不需要进行大量的内存计算，网络传输，性能很高

缺点：
- 极大极大消耗存储资源，feed数据会存储很多份，例如杨幂5KW粉丝，她每次一发博文，消息会冗余5KW份
- 新增关注，取消关注，发布feed的业务流会更复杂


