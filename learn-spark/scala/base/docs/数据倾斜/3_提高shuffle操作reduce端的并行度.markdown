如果第一个和第二个方案,都不适合做,可以使用第三个方案,提高 shuffle 操作的 reduce 并行度,将 reduce task 的数量变多,就可以让每个 reduce task
分配到更少的数据量,这样的话,也许就可以缓解,或者甚至是基本解决掉数据倾斜的问题

### 操作方法
给所有会出发 shuffle 的算子,比如 groupByKey,countByKey,reduceByKey,join.在调用的时候,传入进去一个参数,一个数字,那个数字,就代表了那个
shuffle 操作的 reduce 端的并行度.在进行 shuffle 操作的时候,就会对应着创建指定数量的 reduce task

比如说,原本某个 task 分配的数据特别多,直接 OOM, 内存溢出了,程序没法运行,直接挂掉.按照 log,找到发生数据倾斜的 shuffle 操作,给她传入一个并行
度数字,这样,原先那个 task 分配到的数据,肯定会变少,就至少可以避免 OOM 的情况,程序至少是可以跑的

## 缺陷
治标不治本,它没有从根本上改变数据倾斜的问题.原理没有改变,只是说,尽可能地去缓解和减轻 shuffle reduce task 的数据压力,以及数据倾斜的问题

### 经验
1. 如果情况理想的情况下,提升并行度以后,减轻了数据倾斜的问题,或者甚至可以让数据倾斜的现象忽略不计,这样就最好,就不用做其他的数据倾斜方案了
2. 不太理想的情况,不如之前某个 task 运行特别慢,要 5个 小时,现在稍微快了一点,变成 4个 小时,或者原先运行到某一个 task 就直接 OOM, 现在虽然
不会 OOM 了,但是运行的特别慢, 这种情况,就需要尝试后面四种解决方案