spark 中,堆内存又被划分成了两块,一块是专门用来给 RDD 的 cache,persist 操作进行 RDD 数据缓存用的;另一块,是用来给 spark 算子函数运行使用的,
存放函数中自己创建的对象.  

默认情况下,给 RDD chahe 操作的内存占比是 0.6.
但是某些情况下,cache 不是那么紧张,问题在于 task 算子函数中创建的对象过多,然后内存又不大,导致了频繁的 minor gc,甚至频繁的 full gc,导致频繁
的停止工作,对性能的影响很大.

针对这种情况,可以查看 spark ui 中的运行统计,看到每个 stage 的运行情况,包括每个 task 的运行时间, gc 时间, 如果发现 gc 太频繁,时间太长,此时
就可以适当的调节这个比例

降低 cache 操作的内存占比, 也可以用 persist 操作,选择将一部分缓存的 RDD 数据写入磁盘,配合序列化方式,减少 RDD 的内存占比,减低 cache 操作内
存占比;对应的,算子函数的内存占比就提升了,这个时候,可能就可以减少 minor gc , 同时减少 full gc 的频率

```
spark.storage.memoryFraction    0.6 

```