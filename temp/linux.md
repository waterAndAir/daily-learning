##### 什么是零拷贝？
https://mp.weixin.qq.com/s/xej6klx2q0G1fp82_vKCOg  

作用：减少内核缓冲区和用户缓冲区之间的IO；减少内核态和用户态的上下文切换

|拷贝方式      | CPU拷贝     | DMA拷贝      | 系统调用     | 上下文切换 |
| ---- | ---- | ---- | ---- | --- |
| 传统方式(read + write)  | 2     | 2     | read/write     |  4   |
|  内存映射(mmap+write)    |  1    |  2    |  mmap/write    |    4 |
|  sendfile    |   1   |    2  |  sendfile    |  2  |
|  sendfile + DMA gather copy    |   0   |    2  |  sendfile    |  2  |
|  splice 实现了两个文件描述符之间的数据零拷贝   |   0   |    2  | splice    |  2  |

##### 什么是写时复制？
在某些情况下，内核缓冲区可能被多个进程所共享，如果某个进程想要这个共享区进行 write 操作，由于 write 不提供任何的锁操作，那么就会对共享区中的数据造成破坏，写时复制的引入就是 Linux 用来保护数据的。

写时复制指的是当多个进程共享同一块数据时，如果其中一个进程需要对这份数据进行修改，那么就需要将其拷贝到自己的进程地址空间中。

这样做并不影响其他进程对这块数据的操作，每个进程要修改的时候才会进行拷贝，所以叫写时拷贝。

这种方法在某种程度上能够降低系统开销，如果某个进程永远不会对所访问的数据进行更改，那么也就永远不需要拷贝。

#### C10k 问题
##### 单机支持多大数量的TCP连接？
- 服务端标识一个TCP连接 = [remote_ip + remote_port + local_ip + local_port]
- 假设 local_ip 和 local_port 不变，理论上连接数是： `2的32次方（ip数）×2的16次方（port数）= 2的48次方`

##### IO多路复用(一个进程或线程处理多个连接，就是IO多路复用)
实现方式：
1. 直接循环处理多个连接，一个不成功就会阻塞
2. select: 循环检查多个连接，只处理 ready 的连接，不会阻塞了；但检查的效率低，所以会设置上限
3. poll: 取消了上限，不需要重复初始化，但还是需要逐个排查文件句柄
4. epoll: 只返回状态发生变化的文件句柄；当句柄数大于10后，性能开始优于select和poll，大于 10k 后，性能是select和poll的两个数量级。epoll技术的编程模型就是异步非阻塞回调，也可以叫做Reactor，事件驱动，事件轮循（EventLoop）。Nginx，libevent，node.js这些就是Epoll时代的产物。

##### 激进的 C10M
OS的内核不是解决C10M问题的办法，恰恰相反OS的内核正是导致C10M问题的关键所在。
不要让OS内核执行所有繁重的任务：将数据包处理、内存管理、处理器调度等任务从内核转移到应用程序高效地完成，让诸如Linux这样的OS只处理控制层，数据层完全交给应用程序来处理。


## 内存

### 基本概念
#### 内存映射
- 物理内存只有内核能访问到，进程想要申请内存，需要借助内核为进程提供的独立的虚拟内存空间。而虚拟内存和物理内存是通过内存映射管理的。    
- 内核为每个进程维护了一个`页表`，上面记录了`虚拟内存地址`和`物理内存地址的映射关系。`
- 当进程在通过虚拟内存地址访问内存使，如果在`页表`中找不到对应的`物理内存地址`， 系统会产生一个`缺页异常`，进入内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。
- 内存映射规定了最小单位为 4kb， 所以每次内存映射关联的内存是 4kb 或 4kb 的整数倍。
#### 虚拟内存空间的结构
- 只读段：包括代码和常量等。
- 数据段：包括全局变量等。
- 堆：包括动态分配的内存，从低地址开始向上增长。
- 文件映射段：包括动态库、共享内存等，从高地址开始向下增长。
- 栈：包括局部变量和函数调用的上下文等。栈的大小是固定的，一般是 8 MB。
#### 内存分配与回收
##### malloc() 分配
有两种方式：
- brk(): 分配小块内存(小于128k), 释放后会缓存而不是立即归还给系统。频繁的内存分配和释放会造成内存碎片
- mmap(): 分配大块内存(大于128k)，释放后立即归还给系统。内核管理负担大。

##### 为什么要有虚拟内存？
每个用户进程维护了一个单独的页表（Page Table），虚拟内存和物理内存就是通过这个页表实现地址空间的映射的。

- 提供更大的连续的内存空间
- 进程隔离，数据保护，安全
- 内存映射，延迟分配物理内存，只要在真正需要的时候才会分配
- 共享内存，比如动态库只需要在内存中存储一份，然后将它映射到不同进程的虚拟地址空间中，让进程觉得自己独占了这个文件。

##### 回收方式
- LRU 回收缓存
- swap 将不常访问的内存写到磁盘
- OOM

### Buffer/Cache
- buffer 是对磁盘数据的缓存；
- cache 是对文件数据的缓存；

`读写普通文件时，会经过文件系统，有文件系统负责与磁盘交互；而读写磁盘或分区时，会跳过文件系统；`



##### select,poll和epoll

其实所有的I/O都是轮询的方法,只不过实现的层面不同罢了.

这个问题可能有点深入了,但相信能回答出这个问题是对I/O多路复用有很好的了解了.其中tornado使用的就是epoll的.

selec,poll和epoll区别总结

基本上select有3个缺点:

连接数受限
查找配对速度慢
数据由内核拷贝到用户态
poll改善了第一个缺点

epoll改了三个缺点.

关于epoll的: http://www.cnblogs.com/my_life/articles/3968782.html

[selec,poll和epoll区别总结](http://www.cnblogs.com/Anker/p/3265058.html)

##### io 模型
等待传输资源阶段：
- 阻塞：数据不可用时，IO 请求一直阻塞，直到数据返回
- 非阻塞：数据不可用时，IO 请求立即返回，直到被通知资源可用

使用资源阶段：
- 同步：IO 请求在读取或写入数据时会阻塞，直到读取或写入数据完成
- 异步：IO 请求在读取或写入数据时立即返回，当操作系统处理完 IO 请求，并且将数据拷贝到用户提供的缓冲区后，再通知应用IO请求执行完成。

理解烧开水（传输资源）和倒开水(使用资源)的场景

##### 进程与线程
- 进程是os分配资源的基本单位，线程是独立运行和独立调度的基本单位。
- 进程与进程之间是隔离独立的，各自有各自的堆栈和数据区域，一个线程下最少有一个线程，多个线程共享所在进程的资源。  
- 因为进程间是独立的，所以一个进程崩溃了不会对其他进程产生影响，但进程下所有的线程都会崩溃。所以多进程要比多线程更健壮一些，但是多进程消耗资源比线程大得多。对于一些需要共享变量的并发操作，只能有多线程。

##### 进程间通信的方式
- 管道 pipe：半双工通信，数据只能单向流动，而且只能在父子进程中使用
- 有名管道 named pipe: 半双工，允许无亲缘关系的进程使用
- 信号量:
- 消息队列
- 信号 signal
- 共享内存：最快，配合信号量
- 套接字socket: 用于不在同一台机器上的进程通信

##### 线程通信的方式
- 锁机制：排它锁，共享锁，乐观锁
- 信号
线程中的通信主要用于数据同步，进程中主要用于通信

##### 零拷贝技术
传统文件拷贝流程:
- 调用 read(file) 将文件从用户空间拷贝到内核空间
- cpu 将文件从内核空间拷贝到用户空间
- 调用 write(file), 将文件从用户空间拷贝到内核空间
- cpu 将内核空间的数据复制给网卡设备

Linux 零拷贝 Direct Memory Access，sendfile()：
- DMA: 可以跳过 CPU ，硬件直接读取内存，很多硬件支持DMA, 比如网卡
- 文件不会被读到用户空间
- 文件先被读到 内核空间的 readbuffer， 然后发到 socket buffer， 

## 文件系统

### 基础概念
#### 文件系统
Linux 世界中一切皆文件，每个文件都有两个数据结构：
- 索引节点(index node): 记录 inode编号、文件大小、访问权限、修改日期、数据的位置等元数据，与文件内容一起存于磁盘
- 目录项(directory entry): 记录文件的名字、索引节点指针以及与其他目录项的关联关系，由内核维护与内存，又称目录项缓存

文件系统会将磁盘格式化为三个区域：  
- 超级块： 存储整个文件系统的状态
- 索引节点区： 存储索引节点
- 数据块区： 存储文件数据  

磁盘读写的最小单位是512B大小的扇区，因为太小影响效率，所以文件系统将 `8个扇区` 组成一个 `4kb`大小的逻辑块作为管理数据的最小单元。  
#### 虚拟文件系统
为了是各种文件系统能在一起同时被使用，Linux 内核在用户进程与文件系统之间引入了统一接口 —— VFS(虚拟文件系统)。  

#### 通用块层
通用块层是处于 VFS 与磁盘驱动中间的一个块设备的抽象层：
- 向上，为文件系统和应用程序提供访问块设备的接口，向下，把异构的磁盘设备抽象为统一的接口
-  为 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率。

#### 设备层
包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作。
##### I/O 排序（调度）算法
- NONE：不对IO请求做处理，常用与虚拟机，这时磁盘的调度由虚拟机负责
- NOOP： 先入先出的基本队列，做一些合并，常见于 SSD
- CFQ: 完全公平调度，为每个进程维护一个 IO 调度队列，支持优先级，按时间片均匀分布IO请求，是有很多系统的模式方式
- DeadLine: 分别为读写创建队列，可以提高机械磁盘的吞吐，确保到达最终期限的请求优先被处理，多用在数据库系统。

### 文件系统IO TODO
- 缓冲与非缓冲I/O：缓冲指的是`标准库内部实现的缓存`。非缓冲I/O直接通过系统调用与文件交互
- 直接与非直接I/O：根据是否使用操作系统的`页缓存`，直接IO会跳过操作系统页缓存，直接与文件系统交互；
- 阻塞与非阻塞I/O：根据应用程序是否阻塞自身运行.非阻塞I/O 不会阻塞当前的线程，随后再通过轮询或者事件通知的形式，获取调用的结果
- 同步与异步I/O：根据是否等待响应结果。异步I/O，指应用程序执行I/O操作后，不等待完成响应，而是继续执行。等到这次 I/O完成后，响应会用事件通知的方式，告诉应用程序。

### IO指标
- 使用率：磁盘处理IO的时间比
- 饱和度：磁盘处理IO的繁忙程度。当饱和度为 100% 时，磁盘无法继续处理新的IO请求
- IOPS: 每秒请求数
- 吞吐量：每秒IO请求大小
- 响应时间：IO请求从发到到收到响应的间隔时间

## CPU 
CPU 的消耗除了来自于用于执行程序，还有相当一部分来自于上下文切换，中断(硬中断和软中断)，IO等待。

### 平均负载
平均负载的理想情况应该等于 CPU 数，实际中，将超过 CPU 数量的的 70% 作为警告的阈值。
#### 查看平均负载
```shell script
$ uptime
02:34:03 up 2 days, 20:14,  1 user,  load average: 0.63, 0.83, 0.88
```
从左到右依次表示：
- 当前时间
- 系统运行时间
- 正在登录的用户数
- 过去1分钟，5分钟，15分钟的平均负载（Load Average）， 表示平均活跃进程数， 和 CPU 使用率没有直接关系

#### 辨析平均负载和CPU使用率
平均负载： 单位时间内处于可运行状态和不可中断状态的进程数  
CPU 使用率： 单位时间内CPU的繁忙情况  

- CPU 密集型进程： 平均负载和CPU使用率变化一致，都会升高
- I/O 密集型进程： 等待IO属于不可中断状态，平均负载会升高,但 CPU 此时可能在空等，所以使用率不一定高
- 进程较多，等待CPU调度也会导致平均负载和CPU使用率同时升高

### CPU 使用率

CPU 使用率 = 1 - 空闲时间/总CPU时间  

一般性能分析工具，会取一个时间段计算平均CPU使用率：  

CPU 平均使用率 = 1 - （空闲时间2 - 空闲时间1）/ (总CPU时间2 - 总CPU时间1)  

所以在对比不同工具分析的时候，要注意它们的间隔时间是否一致，top 一般为 3 秒，而 ps 是取的进程的整个生命周期  

根据运行任务的不同，又被分为以下几种：  
- 用户CPU: 
- 系统CPU 
- 等待I/O CPU
- 软中断和硬中断

#### CPU 使用率相关的指标
```
top - 16:03:50 up 10:37,  3 users,  load average: 0.06, 0.01, 0.00
Tasks: 104 total,   1 running,  57 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.0 sy,  0.0 ni, 99.7 id,  0.0 wa,  0.0 hi,  0.3 si,  0.0 st
KiB Mem :  4040012 total,  3407476 free,    93848 used,   538688 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  3708964 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
    1 root      20   0   77932   9048   6680 S  0.0  0.2   0:02.09 systemd
    2 root      20   0       0      0      0 S  0.0  0.0   0:00.00 kthreadd
    4 root       0 -20       0      0      0 I  0.0  0.0   0:00.00 kworker/0:0H
    6 root       0 -20       0      0      0 I  0.0  0.0   0:00.00 mm_percpu_
```
- us(user): 用户态 CPU 时间。不包括 nice 时间，但包括了 guest 时间
- ni(nice): 低优先级用户态 CPU 时间，也就是进程的 nice 值被调整为 1-19 之间时的 CPU 时间。nice 可取值范围是 -20 到 19，数值越大，优先级越低
- sys(system): 内核态 CPU 时间
- id(idle): 代表空闲时间。不包括等待 I/O 的时间（iowait）
- wa(iowait): 代表等待 I/O 的 CPU 时间
- hi(irq): 代表处理硬中断的 CPU 时间
- si(softirq): 代表处理软中断的 CPU 时间
- st(steal): 代表当系统运行在虚拟机中的时候，被其他虚拟机占用的 CPU 时间
- guest: 代表通过虚拟化运行其他操作系统的时间，也就是运行虚拟机的 CPU 时间
- gnice(guest_nice): 代表以低优先级运行虚拟机的时间

### CPU 上下文
CPU 会不断的轮换正在执行的进程，以此实现多任务的效果，在每次切换的时候，需要系统为准备好寄存器和计数器，它们就是CPU的上下文：  

- 寄存器：CPU 内置的容量小、但速度极快的内存。
- 计数器：存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。

过多的上下文切换，会把CPU时间消耗在寄存器、内核栈以及虚拟内存等数据的保存和恢复上，从而缩短进程真正运行的时间，导致系统的整体性能大幅下降。

根据任务的不同，CPU切换可以分为三个场景：进程上下文切换，线程上下文切换，中断上下文切换
#### 进程上下文切换
进程的运行在内核空间时称为内核态，运行在用户空间时称为用户态：

- 内核态：具有最高权限，可以直接访问所有资源
- 用户态：部分资源访问受限，必须通过系统调用将进程转化到内核态才能访问受限的资源，比如内存

##### 进程内的上下文切换（特权模式切换）
进程在进行系统调用时，也会发生 CPU 上下文切换。进行进行系统调用时，CPU 寄存器要将用户态的指令位置保存先来，再将内核态的指令位置更新到寄存器上，才可以执行，
执行结束后，CPU 寄存器需要相似的步骤切换回用户态继续执行用户代码。所以一次系统调用会发生两次 CPU 上下文切换。  

系统调用过程中一直在一个进程内，所有不需要切换进程的虚拟内存，栈等资源。  这个过程比较快

##### 进程间的上下文切换
进程是由内核来管理和调度的，进程的切换只能发生在内核态。
进程的上下文不仅包括了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的状态，所以切换进程很耗资源。    

###### 进程上下文切换的场景
- 程序执行完终止，释放 CPU，从就绪队列中取出新的进程运行
- CPU 根据进程的优先级和等待CPU的时间选择进程进行切换，CPU 资源被划分为一段段的时间片，当某个进程的时间片耗尽了，就会进行上下文切换
- 当资源(比如内存)不足时，会将进程挂起等待资源满足后再执行，这时会切换上下文，系统会调度其他进程运行
- 进程调用 sleep 函数主动挂起
- 当有优先级高的进程时，会进行上下文切换，挂起优先级低的进程
- 发生硬件(比如网卡 硬盘 键盘等)中断, 网卡接收到一个数据包，也会发出一个中断，此时CPU上执行的进程会被挂起，转而执行内核上的中断服务。

#### 线程上下文切换

- 线程是调度的基本单位， 内核中的任务调度，实际上的调度对象是线程
- 进程给线程提供了虚拟内存、全局变量等资源
- 两个线程属于不同进程时，切换过程就跟进程上下文切换是一样的
- 两个线程属于同一个进程时，只需要切换线程的私有数据、寄存器等不共享的数据

#### 中断上下文切换
中断处理比进程拥有更高的优先级， 中断上下文切换不涉及到进程的用户态，只包括内核态中断进程的状态，包括CPU 寄存器、内核堆栈、硬件中断参数等。
大部分中断都会很快执行，但大量的中断切换还是会降低整体性能。

### 中断
中断是响应硬件设备请求的一种异步的事件处理机制，它会打断进程的正常调度和执行，然后调用内核中的中断处理程序来响应设备的请求。

CPU 为了快速处理中断程序，将其过程分为了两个步骤，硬中断和软中断：
- 硬中断：直接处理硬件请求，在中断禁止模式下快速运行，它会打断CPU正在执行的任务，立即执行中断处理程序
- 软中断：由内核触发，延迟处理上一步未完成的工作，通常以内核线程的方式运行，每个CPU对应一个软中断内核线程，名为 `ksoftirqd/CPU编号`；软中断除了来自于硬中断，内核自定义的一些事件也属于软中断，比如内核调度和RCU锁

以网卡设备接收数据包中断事件为例：  
- 网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。
- 硬中断：将网卡数据读到内存，更新一下硬件寄存器的状态（表示数据已经读好了），最后再发送一个软中断信号，通知下一步的处理
- 软中断：从内存中找到网络数据，再按照网络协议栈，对数据进行逐层解析和处理，直到把它送给应用程序。

#### 查看软中断和内核线程
`/proc/softirqs` 提供了软中断的运行情况  
`/proc/interrupts`提供了硬中断的运行情况。

```shell script
root@ubuntu-vm:~$ cat /proc/softirqs
                    CPU0       CPU1       CPU2       CPU3
          HI:          1          0          0          0
       TIMER(定时中断): 1020189927  983392064  980802249  998314540
      NET_TX(网络发送中断):          6          0          0          0
      NET_RX(网络接收中断):  467253728  670205491  196150048  389768608
       BLOCK:          0          0          0          0
BLOCK_IOPOLL:          0          0          0          0
     TASKLET:          3         13          1          1
       SCHED(内核调度):  649436485  606246066  595990791  587987098
     HRTIMER:          0          0          0          0
         RCU(内核常用的锁):  859343334  824079502  817872736  827593042
```
```shell script
# 每个CPU对应一个软中断内核线程，查看这些线程的运行状态，在[]中表示是内核线程
root@ubuntu-vm:~$ ps aux | grep softirqd
root         3  0.0  0.0      0     0 ?        S     2019  13:01 [ksoftirqd/0]
root        13  0.0  0.0      0     0 ?        S     2019  11:36 [ksoftirqd/1]
root        18  0.0  0.0      0     0 ?        S     2019   5:18 [ksoftirqd/2]
root        23  0.0  0.0      0     0 ?        S     2019   6:18 [ksoftirqd/3]
```

#### 软中断事件过载问题
当软中断事件的频率过高时，内核线程也会因为 CPU 使用率过高而导致软中断处理不及时，进而引发网络收发延迟、调度缓慢等性能问题。  

但实际生产中，软中断遇到的性能瓶颈大多是网络收发类型的，特别是网络接收的软中断，比如web服务器遇到了 SYN FLOOD 攻击，这时就应该使用 sar 和 tcpdump 找出正在
产生大量软中断的网卡以及源IP。

### 优化
#### 应用程序层
- 编译器优化
- 算法优化
- 异步处理
- 多线程替换多进程
- 缓存

#### 系统层
- CPU 绑定： 进程绑定到一个或多个CPU上，提高CPU缓存命中率，减少跨CPU调度
- CPU 独占： CPU 由指定的进程独占，不允许其他进程使用这些CPU
- 优先级调整： 调整进程的 nice 值，降低非核心进程的优先级，提高核心进程的优先级
- 设置进程资源限制： cgroup， 防止耗尽系统资源
- NUMA（Non-Uniform Memory Access）: 
- 中断的负载均衡： 开启 irqbalance 服务或者配置 smp_affinity，就可以把中断处理过程自动负载均衡到多个 CPU 上

































