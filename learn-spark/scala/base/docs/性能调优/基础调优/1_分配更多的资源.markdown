### 可分配的资源
executor, cpu per executor, memory per executor,driver memory

```
/usr/local/spark/bin/spark-submit \
--class cn.spark.sparktest.core.WordCountCluster \
--num-executors 3 \  配置executor的数量
--driver-memory 100m \  配置driver的内存（影响不大）
--executor-memory 100m \  配置每个executor的内存大小
--executor-cores 3 \  配置每个executor的cpu core数量
/usr/local/SparkTest-0.0.1-SNAPSHOT-jar-with-dependencies.jar \
```

### 调节到多大
#### Spark Standalone
评估每天机器还能够使用的内存和CPUcore,比如每台机器能提供4G内存,2个CPUcore,20台机器就可以分配 20 个 executor,平均每个
executor 4G 内存,2个 CPUcore,并行度是40
#### Yarn
评估要提交到的资源队列,大概有多少资源.
比如有 500G 内存,100 个 CPUcore,50个 executor,平均每个 executor 10G 内存,2个CPUcore

### 增加资源可以使性能优化的原理
#### 1.增加 executor 
executor 的数量与可以并行执行的 task 数量正相关.
比如有 3个 executor,每个 executor 有两个 CPUcore, 那么同时能够并行的执行的task, 就是 6 个,这 6 个 执行完已有,再换下一批 6 个 task
增加了 executor 数量后,可并行执行的task就增加了,执行的速度也就相应的变快

#### 2. 增加 executor 的内存量
(1)如果需要对 RDD 进行 cache, 更多的内存就可以缓存更多的数据,减少磁盘IO  
(2)对于 shuffle 操作, reduce 端,会需要内存来存放拉取过来的数据并进行聚合.如果内存不够,也会写入磁盘.
(3)对于 task 执行,可能会创建很多对象.如果内存比较小,可能会导致频繁的 GC

#### 3. 增加每个 executor 的CPUcore
可以增加执行的并行能力,并行能力与 executor 数量和 cpucore 数量线性相关

