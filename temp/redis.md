### 数据结构
- string : 字节数组，每个字节 8 bit， 二进制安全，可存任何格式，字段或json对象或图片，最大512M
- hash : 类似于数据库表，适合存储对象；散列表
- list : 双向循环链表，两端插入高效，中间插入效率越来越低，按插入顺序排序，普遍用来实现消息队列，需要注意
- set：集合类型，无序不重复，方便实现交并补运算，比如共同好友
- zset：跳表，给集合中每个元素加入一个分数用于排序，可以实现好友亲密度
- bitmap：适合存储bool值, count操作的不是bit级，而是byte级
- HyperLogLog：提供不精确的去重计数方案，比如统计 uv，有 1% 左右误差，占据一定 12k 的空间。只能统计，不是判断是佛存在
- Geo：用于存储地理位置，可以解决附近的人等需求，底层其实是zset，所以数据量不能过大，es？
- Pub/Sub
- Redis Module： 
- - BloomFilter： 去重判断，用于判断某个值是否存在，节省90%空间，推荐系统推荐内容去重，爬虫系统url去重，垃圾邮件。与 HyperLogLog 辨析理解。
- - RedisSearch
- - Redis-ML
- - redis-cell， 限流模块，漏斗算法
- Stream：


##### 压缩列表
- 元素的大小可以不同，支持多种类型的元素
- 节省内存
- 内存空间连续，读取效率高

使用了 压缩列表的 redis 结构：hash，list，

### redis 高可用
#### redis 持久化　rdb快照 和 aof 日志配合

#### 哨兵 高可用（单master多slave）
哨兵适合数据量小的场景。  
集群监控，消息通知，故障转移
#### 集群 可扩展（cluster 多master多slave）
自动将数据进行分片，每个master 放一部分数据，实现海量存储，不需要手动配置复制和哨兵。  

cluster 模式下，每个 redis 开放两个端口，一个 6379， 一个 16379，前者提供服务，后者节点间通信，完成故障发现和转移。  

### 数据分布算法

#### 原始 hash 算法
根据节点数量对 key 取模， 然后存到响应符的节点，一点有一个节点故障，大部分数据就要重新取模写入缓存，不能接受

#### 一致性hash
普通的一致性hash，计算key的hash值，找到圆环上距离最近的节点，节点宕机后，只有该节点受到影响。  

针对一致性hash的缺点，可以引入虚拟节点，

###### hash solt 算法

redis 有固定的 16384 个 hash solt，当接收到写请求后，会对 key计算CRC16值，然后再对16384取模，这样就可以获取key对应的hash slot

redis cluster 中每个 master 都会持有部分slot，当增加一个master时，就将其他master的hash slot部分移动过去，减少一个master，就将它的hash slot移动到其他master上去。

这样就可以高效的解决节点变化时造成的数据转移开销。

### 分布式锁
```
set lock_name true ex 10 nx
...
del lock_name
```
```
EX seconds – 设置过期时间，单位秒
PX milliseconds – 设置过期时间，单位毫秒
NX – key 不存在才设置 key 的值
XX – key 已经存在才可以设置 key 的值
```
#### 超时问题
不要执行过长的任务。给 value 设置随机值，使用lua语言在执行 del 前先判断value是否一致。

#### 锁冲突
抛出异常，由客户端决定是否重连  
把冲突的请求的消息加入另一个队列，另做处理


### 10w个key是以某个固定的已知的前缀开头的，如果将它们全部找出来？

使用keys指令可以扫出指定模式的key列表。redis的单线程的。keys指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用scan指令，scan指令可以无阻塞的提取出指定模式的key列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用keys指令长。  

之所以返回的结果可能多可能少，是因为不是所有的槽位上都会挂接链表，有些槽位可能是空的，还有些槽位上挂接的链表上的元素可能会有多个   

scan 的遍历顺序非常特别。它不是从第一维数组的第 0 位一直遍历到末尾，而是采用了高位进位加法来遍历。之所以使用这样特殊的方式进行遍历，是考虑到字典的扩容和缩容时避免槽位的遍历重复和遗漏。


### 如果有大量的key需要设置同一时间过期，一般需要注意什么？

- reids 把所有设置了过期时间的key放到一个单独的 map，定期遍历
- 惰性删除: 访问key时判断是否过期

如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个`随机值`，使得过期时间分散一些。

### Pipeline有什么好处，为什么要用pipeline？

可以将多次IO往返的时间缩减为一次，前提是pipeline执行的指令之间没有因果相关性。使用redis-benchmark进行压测的时候可以发现影响redis的QPS峰值的一个重要因素是pipeline批次指令的数目。

### 限流  
高并发应用阻止大量请求对系统施压。  
控制用户行为。（发帖，点赞，回复） 

简单限流 用 zset 实现时间滑动窗口， value 和 score 都用当前时间。如果访问量大，不适用。   

漏斗限流 

#### 漏斗限流
redis-cell：
```
 cl.throttle key:reply 15 30 60 1
                            ▲  ▲  ▲  ▲
                            |  |  |  └───── need 1 quota (可选参数，默认值也是1)
                            |  └──┴─────── 30 operations / 60 seconds 这是漏水速率
                            └───────────── 15 capacity 这是漏斗容量

```

漏桶和令牌桶的关键区别：计算剩余令牌（Token）或配额（Quota）。  
漏桶算法是令牌消耗的速度恒定，生成的速度可变。  
令牌桶算法是令牌生成的速度很定，消耗的速度可变。

#### 安全问题注意点
- 危险命令起别名：rename-command flushall
- 指定监听的 IP 地址，bind 10.100.20.13
- 用户名密码

## 其他问题
##### Redis 为什么使用单线程？
- Redis 服务使用单线程模型处理绝大多数的网络请求
- Redis 服务增加了多个非阻塞的删除操作，例如：UNLINK、FLUSHALL ASYNC 和 FLUSHDB ASYNC
- 使用单线程模型能带来更好的可维护性，方便开发和调试；
- 使用单线程模型也能并发的处理客户端的请求 （IO多路复用）
- 多线程主要是为了用到多核CPU，但Redis 服务中运行的绝大多数操作的性能瓶颈都不是 CPU；因为操作是在内存中，不需要IO， 一台普通的linux机器可以轻松 1百万QPS

##### redis6.0 中的多线程
在 Redis 中虽然使用了 I/O 多路复用，并且是基于非阻塞 I/O 进行操作的，但 I/O 的读和写本身是堵塞的，
比如当 socket 中有数据时，Redis 会通过调用先将数据从内核态空间拷贝到用户态空间，
再交给 Redis 调用，而这个拷贝的过程就是阻塞的，当数据量越大时拷贝所需要的时间就越多，而这些操作都是基于单线程完成的。

在 Redis 6.0 中新增了多线程的功能来提高 I/O 的读写性能，他的主要实现思路是将主线程的 IO 读写任务拆分给一组独立的线程去执行，这样就可以使多个 socket 的读写可以并行化了，但 Redis 的命令依旧是由主线程串行执行的。
##### redis 为什么使用子进程进行RDB快照
- 通过 fork 创建的子进程能够获得和父进程完全相同的内存空间，父进程对内存的修改对于子进程是不可见的，两者不会相互影响；
- 通过 fork 创建子进程时不会立刻触发大量内存的拷贝，内存在被修改时会以页为单位进行拷贝，这也就避免了大量拷贝内存而带来的性能问题；

  
##### redis 为什么这么快
- 内存
- 数据结构简单，算法复杂度低
- 单线程，没有锁，没有上下文切换
- io 多路复用，非阻塞id

##### redis 为什么变慢了？
- 一次操作的对象过大，比如用了 keys， 应该用 scan
- AOF fork 进程或 rsync 阻塞
- 内存不够了 发生了 (swap)

##### redis 优化攻略
- key,value 尽量小，必要的时候，要序列化或压缩value
- 使用延迟删除 unlink
- 设置必要的超时时间
- 禁用危险的指令： keys
- 控制 Hash、Set、Sorted Set 的大小
- 分析慢日志
- 使用 Pipeline 批量操作数据，RedisCluster中使用pipeline时必须满足pipeline打包的所有命令key在RedisCluster的同一个slot上。
- 避免大量数据同时失效
- 使用连接池
- 禁用 THP 特性
- 使用分布式
- 注意合理的持久化策略
- 限制 redis 的内存，避免发生 swap 


##### redis 分布式集群倾斜问题
1. 数据容量倾斜
2. 请求量倾斜

原因：
- 没有考虑热点key，导致那里有热点key，那里就有倾斜
- 存在大key，大 key 在哪里，哪里就倾斜
- 使用了 hash_tag, 导致数据槽分配不均匀
- 使用了 monitor ，keys 等指令，导致节点内存量过大

分析工具：
- 热key： redis-faina
- 大key： redis-cli --bigkeys

解决：
- 热key，大key 要分散，或用本地缓存
- 平均分配槽，一定要用 hash_tag 要保证心中有数


##### redis 其他应用
- 分布式锁(string: setnx)
- 计数器(string)
- 队列(list)
- 抽奖(set srandmember key count)
- 点赞签到(set)
- 排行榜，延迟队列(zset)
# 其他
https://mp.weixin.qq.com/s/8d65YQEzO0jn7Vq564giZQ





#### 保证缓存与数据库的双写一致性
##### Cache Aside(旁路缓存策略)
读过程：
1. 查缓存
2. 缓存命中，返回数据
3. 缓存miss，查数据库
4. 查到数据后，写入缓存

写过程：
1. 更新数据库
2. **删除缓存**


分布式场景下，这种方式理论上还是会出现数据不一致。但因为`写数据库`耗时会远超`写缓存`。

##### read/write throuth 通读缓存
- cdn，反向代理缓存

##### write behind


#### 缓存穿透
场景:短时间内大量用户注册，每个请求后端都要判断注册信息中的phone，email是不是已经注册过了，这一步需要查缓存，缓存中没有就去查库。  

问题就出在这个，如果有大量的用户同时注册，就会发生缓存穿透
##### 布隆过滤器
将所有用户信息的phone或email 放入布隆过滤器，新用户注册时，判断该用户的 phone， email 在不在布隆过滤器，如果不在，就允许用户继续注册，如果在，就去查缓存，查库，看看是不是真的在。

##### 参数校验

#### 缓存击穿： 狗桩效应(dog-pile-effect)

一个热点数据缓存失效，瞬间引起一大堆数据库请求。   

- 如果热点数据缓存实现，直接返回失败，然后用一个异步线程去查数据库，填回缓存
- 热点缓存失效后，建立分布式锁，同步去查数据库，填充缓存，其他请求或等待锁释放后查缓存，或直接返回失败

#### 缓存雪崩
- 大量key同时失效
- 给key的过期时间加随机数，热点数据不过期，数据均匀分布到节点上
- 高可用
- 可扩展

#### 提高命中率
- 高可用
- 可扩展


#### CDN 
静态资源应该就近访问
